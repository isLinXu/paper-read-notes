
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>FCOS &#8212; 论文阅读笔记</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css?v=7f9a90b1" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=40d2fe7a"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Notes/detection/FCOS';</script>
    <link rel="icon" href="../../_static/panda.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="SSD" href="SSD.html" />
    <link rel="prev" title="FPN" href="FPN.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="论文阅读笔记 - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="论文阅读笔记 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Method/index.html">论文阅读指南</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Method/efficent_read_paper.html">高效阅读方法及流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/how_to_read_paper.html">如何阅读论文</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/paper_10_question.html">论文速读十问</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/read_important_tips.html">读论文与口头报告的几项重点</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/reference.html">参考材料</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../List/index.html">论文阅读清单</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../List/basis.html">神经网络基础(basis)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/attention.html">注意力部分(attention)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/batch_normalization.html">批量&amp;正则化(batch&amp;normalization)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/classification.html">图像分类(CLAS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/convolutional.html">高级卷积网络知识(Convolutional)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/gan.html">AI合成部分(GAN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/nlp.html">自然语言处理(NLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/objectdetection.html">目标检测(OBJ)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/rnn.html">循环神经网络(RNN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/segementation.html">目标分割(SEG)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/transformer.html">Transformer</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/multimodal.html">多模态(MultiModal Learning)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/llm.html">大语言模型(Large Language Models)</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">论文阅读笔记</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../mm-l/index.html">MultiModal Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mm-l/blip-v1.html">BLIP: Bootstrapping Language-Image Pre-training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mm-l/blip-v2.html">BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../llm/index.html">Large Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../llm/opt.html">OPT: OPT : Open Pre-trained Transformer Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v1.html">GPT-v1:Improving Language Understanding by Generative Pre-Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v2.html">GPT-v2:Language Models are Unsupervised Multitask Learners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v3.html">GPT-v3:Language Models are Few-Shot Learners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v4.html">GPT-v4:GPT-4 Technical Report</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">Object Detection</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="summary.html">summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="RCNN.html">RCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Fast%20R-CNN.html">Fast R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Faster%20R-CNN.html">Faster R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mask%20R-CNN.html">Mask R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="FCN.html">FCN</a></li>
<li class="toctree-l3"><a class="reference internal" href="R-FCN.html">R-FCN</a></li>
<li class="toctree-l3"><a class="reference internal" href="FPN.html">FPN</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">FCOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="SSD.html">SSD</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mobilenet-SSDv2.html">Mobilenet-SSDv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="VarifocalNet.html">论文阅读笔记</a></li>

<li class="toctree-l3"><a class="reference internal" href="OneNet.html">OneNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mask%20R-CNN.html">Mask R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Cascade-RCNN.html">Cascade-RCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="RetinaNet.html">RetinaNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="FemtoDet.html">FemtoDet</a></li>
<li class="toctree-l3"><a class="reference internal" href="SparseInst.html">SparseInst</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv1.html">YOLOv1</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv2.html">YOLOv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv3.html">YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv4.html">YOLOv4</a></li>
<li class="toctree-l3"><a class="reference internal" href="Scaled-YOLOv4.html">Scaled-YOLOv4</a></li>
<li class="toctree-l3"><a class="reference internal" href="Edge-YOLO.html">Edge-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="MS-DAYOLO.html">MS-DAYOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="ASFF.html">ASFF</a></li>
<li class="toctree-l3"><a class="reference internal" href="ATSS.html">ATSS</a></li>
<li class="toctree-l3"><a class="reference internal" href="SABL.html">SABL</a></li>
<li class="toctree-l3"><a class="reference internal" href="SM-NAS.html">SM-NAS</a></li>
<li class="toctree-l3"><a class="reference internal" href="TSD.html">TSD</a></li>
<li class="toctree-l3"><a class="reference internal" href="RDSNet.html">RDSNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="CenterMask.html">CenterMask</a></li>
<li class="toctree-l3"><a class="reference internal" href="EfficientDet.html">EfficientDet</a></li>
<li class="toctree-l3"><a class="reference internal" href="Simple%20Multi-dataset%20Detection.html">Simple Multi-dataset Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOX.html">YOLOX</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv6.html">YOLOv6</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOv1.html">PP-YOLOv1</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOv2.html">PP-YOLOv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOE.html">PP-YOLOE</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOF.html">YOLOF</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOP.html">YOLOP</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOR.html">YOLOR</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOS.html">YOLOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv7.html">YOLOv7</a></li>
<li class="toctree-l3"><a class="reference internal" href="Dy-yolov7.html">DY-yolov7</a></li>
<li class="toctree-l3"><a class="reference internal" href="Gold-YOLO.html">Gold-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv6_v3.0.html">YOLOv6</a></li>
<li class="toctree-l3"><a class="reference internal" href="DAMO-YOLO.html">DAMO-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="ViT-YOLO.html">ViT-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLO-MS.html">YOLO-MS</a></li>
<li class="toctree-l3"><a class="reference internal" href="Detr.html">DETR</a></li>
<li class="toctree-l3"><a class="reference internal" href="RT-DETR.html">RT-DETR</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv9.html">YOLOv9</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOOC.html">YOLOOC</a></li>
<li class="toctree-l3"><a class="reference internal" href="FemtoDet.html">FemtoDet</a></li>
<li class="toctree-l3"><a class="reference internal" href="MS-DAYOLO.html">MS-DAYOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="OneNet.html">OneNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="Sparse%20R-CNN.html">Sparse R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="SparseInst.html">SparseInst</a></li>
<li class="toctree-l3"><a class="reference internal" href="OWL-ViT.html">OWL-ViT</a></li>
<li class="toctree-l3"><a class="reference internal" href="OWLv2.html">OWLv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="RTMDet.html">RTMDet</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLO-World.html">YOLO-World</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOOC.html">YOLOOC</a></li>
<li class="toctree-l3"><a class="reference internal" href="MDETR.html">MDETR</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv10.html">YOLOv10</a></li>
<li class="toctree-l3"><a class="reference internal" href="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B020%E5%B9%B4.html"><strong>目标检测二十年：一项综述</strong></a></li>





<li class="toctree-l3"><a class="reference internal" href="yolo%E7%BB%BC%E8%BF%B0.html"><strong>YOLO的全面综述：从YOLOv1到YOLOv8及未来</strong></a></li>




















</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Read/index.html">论文阅读记录</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Summary/index.html">论文阅读总结</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes/edit/main/Notes/detection/FCOS.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes/issues/new?title=Issue%20on%20page%20%2FNotes/detection/FCOS.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/Notes/detection/FCOS.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>FCOS</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="fcos">
<h1>FCOS<a class="headerlink" href="#fcos" title="Link to this heading">#</a></h1>
<p><strong>标题：</strong> FCOS: Fully Convolutional One-Stage Object Detection</p>
<p><strong>作者：</strong> Zhi Tian, Chunhua Shen, Hao Chen, Tong He</p>
<p><strong>机构：</strong> The University of Adelaide, Australia</p>
<p><strong>摘要：</strong></p>
<ul class="simple">
<li><p>提出了一种全新的目标检测框架，名为FCOS（Fully Convolutional One-Stage Object Detection）。</p></li>
<li><p>该框架模拟语义分割的方式，采用逐像素预测的方法来解决目标检测问题。</p></li>
<li><p>与现有基于锚框（anchor boxes）的方法不同，FCOS无需预定义锚框，也不需要候选区域（proposals）。</p></li>
<li><p>通过消除锚框相关的复杂计算和超参数，FCOS在简化模型的同时，还取得了更好的检测精度。</p></li>
</ul>
<p><strong>引言：</strong></p>
<ul class="simple">
<li><p>目标检测是计算机视觉领域的基础任务之一，需要预测图像中每个感兴趣实例的边界框和类别标签。</p></li>
<li><p>当前主流的目标检测器（如Faster R-CNN, SSD, YOLOv2, v3）依赖于预定义的锚框，但这些方法存在一些缺点，比如对锚框尺寸、纵横比和数量敏感，难以处理形状变化大的物体，训练时正负样本不平衡，以及计算复杂度高等。</p></li>
</ul>
<p><strong>相关工作：</strong></p>
<ul class="simple">
<li><p>锚框基础的检测器：继承了传统的滑动窗口和基于提议的方法，如Fast R-CNN。</p></li>
<li><p>无锚框检测器：例如YOLOv1，它不使用锚框，而是在物体中心附近的点预测边界框。</p></li>
</ul>
<p><strong>方法：</strong></p>
<ul class="simple">
<li><p>FCOS通过在每个前景像素上预测一个4D向量（l, t, r, b）来编码边界框的位置。</p></li>
<li><p>引入了“center-ness”分支，用于预测像素到其对应边界框中心的偏差，以抑制低质量的检测框。</p></li>
</ul>
<p><strong>实验：</strong></p>
<ul class="simple">
<li><p>在COCO数据集上进行实验，使用COCO trainval35k分割进行训练，minival分割进行验证。</p></li>
<li><p>展示了FCOS与现有一阶段检测器相比具有更好的性能，尤其是在AP（平均精度）指标上。</p></li>
</ul>
<p><strong>结论：</strong></p>
<ul class="simple">
<li><p>FCOS是一个简单而强大的目标检测框架，无需锚框，可以作为许多其他实例级别任务的替代方案。</p></li>
</ul>
<p>回答问题</p>
<ol class="arabic simple">
<li><p><strong>这篇论文做了什么工作，它的动机是什么？</strong></p>
<ul class="simple">
<li><p>论文提出了FCOS，一个无锚框的一阶段目标检测框架。动机是简化目标检测流程，消除与锚框相关的复杂计算和超参数，同时提高检测精度。</p></li>
</ul>
</li>
<li><p><strong>这篇论文试图解决什么问题？</strong></p>
<ul class="simple">
<li><p>论文试图解决基于锚框的目标检测方法中的多个问题，包括对锚框尺寸、纵横比和数量的敏感性，处理形状变化大的物体的困难，训练时正负样本不平衡，以及计算复杂度高。</p></li>
</ul>
</li>
<li><p><strong>这是否是一个新的问题？</strong></p>
<ul class="simple">
<li><p>目标检测中的锚框问题并不是一个新问题，但提出无锚框的一阶段检测框架是一个新颖的解决方案。</p></li>
</ul>
</li>
<li><p><strong>这篇文章要验证一个什么科学假设？</strong></p>
<ul class="simple">
<li><p>论文要验证的科学假设是：无锚框的一阶段目标检测框架能够实现与基于锚框的方法相当的或更好的检测精度，同时简化模型结构。</p></li>
</ul>
</li>
<li><p><strong>有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</strong></p>
<ul class="simple">
<li><p>相关研究包括基于锚框的检测器（如Faster R-CNN, SSD, YOLOv2, v3）和无锚框检测器（如YOLOv1, CornerNet）。这些研究可以根据是否使用锚框进行归类。领域内值得关注的研究员包括Kaiming He、Ross Girshick、Tsung-Yi Lin等。</p></li>
</ul>
</li>
<li><p><strong>论文中提到的解决方案之关键是什么？</strong></p>
<ul class="simple">
<li><p>解决方案的关键是FCOS框架，它采用逐像素预测的方式，无需预定义锚框，并通过“center-ness”分支来提高检测质量。</p></li>
</ul>
</li>
<li><p><strong>论文中的实验是如何设计的？</strong></p>
<ul class="simple">
<li><p>实验设计包括使用COCO数据集进行训练和验证，以及对比FCOS与其他一阶段和两阶段目标检测器的性能。</p></li>
</ul>
</li>
<li><p><strong>用于定量评估的数据集上什么？代码有没有开源？</strong></p>
<ul class="simple">
<li><p>用于定量评估的数据集是COCO。论文提供了代码的链接：tinyurl.com/FCOSv1，表明代码已经开源。</p></li>
</ul>
</li>
<li><p><strong>论文中的实验及结果有没有很好地支持需要验证的科学假设？</strong></p>
<ul class="simple">
<li><p>是的，实验结果表明FCOS在AP等指标上超越了现有的一阶段检测器，支持了论文的科学假设。</p></li>
</ul>
</li>
<li><p><strong>这篇论文到底有什么贡献？</strong></p>
<ul class="simple">
<li><p>论文的贡献包括提出了一个新颖的无锚框一阶段目标检测框架FCOS，简化了目标检测流程，并在保持计算效率的同时提高了检测精度。</p></li>
</ul>
</li>
<li><p><strong>下一步呢？有什么工作可以继续深入？</strong></p>
<ul class="simple">
<li><p>下一步的工作可以包括进一步优化FCOS框架，探索在不同数据集和实际应用场景中的性能，以及将FCOS扩展到其他计算机视觉任务，如实例分割和关键点检测。</p></li>
</ul>
</li>
</ol>
<hr class="docutils" />
<img width="652" alt="fcos-fig1" src="https://github.com/isLinXu/issues/assets/59380685/6b94067b-87c6-46f7-a447-33f81caed293">
<p>图表展示了FCOS（Fully Convolutional One-Stage Object Detection）算法的工作原理及其在某些情况下的局限性。</p>
<p>左图展示了FCOS如何通过预测一个4D向量（l, t, r, b）来编码每个前景像素的边界框位置。这个4D向量表示从当前像素到边界框左、上、右、下边界的距离。训练过程中，这些预测是通过监督学习的方式，利用真实的边界框信息进行指导。</p>
<p>右图展示了一个问题，即当一个位置处于多个边界框内时，可能会出现模糊的情况，不确定该位置应该回归到哪个边界框。这种情况在重叠的边界框中尤为明显，可能会导致检测结果的不准确。</p>
<p>结合摘要，可以总结如下：</p>
<p>FCOS是一种全卷积单阶段目标检测算法，通过预测每个前景像素到边界框边界的距离来确定目标的位置。然而，当一个像素点位于多个重叠的边界框内时，可能会出现回归目标不明确的问题。这种模糊性可能会影响检测的准确性，需要进一步的策略来解决这一问题。</p>
<hr class="docutils" />
<img width="1338" alt="fcos-fig2" src="https://github.com/isLinXu/issues/assets/59380685/4ea5da9b-6796-4116-876c-5bf9f1c1424c">
<p>图表展示了FCOS（Fully Convolutional One-Stage Object Detection）算法的网络结构，具体分为三个部分：Backbone、Feature Pyramid和Head。</p>
<ol class="arabic simple">
<li><p><strong>Backbone</strong>：</p>
<ul class="simple">
<li><p>C3, C4, C5表示主干网络的特征图。</p></li>
<li><p>这些特征图的尺寸分别为H/8, H/16, H/32（H和W分别表示输入图像的高度和宽度）。</p></li>
<li><p>这些特征图通过主干网络（例如ResNet）提取。</p></li>
</ul>
</li>
<li><p><strong>Feature Pyramid</strong>：</p>
<ul class="simple">
<li><p>P3, P4, P5, P6, P7表示特征金字塔的特征层。</p></li>
<li><p>这些特征层是从C3, C4, C5特征图通过上采样和下采样操作生成的。</p></li>
<li><p>特征金字塔的目的是在不同尺度上进行目标检测，以便更好地处理不同大小的目标。</p></li>
</ul>
</li>
<li><p><strong>Head</strong>：</p>
<ul class="simple">
<li><p>每个特征层（P3到P7）都连接到一个Head模块。</p></li>
<li><p>Head模块包括三个分支：分类分支、中心度分支和回归分支。</p></li>
<li><p>分类分支用于预测每个像素点的类别。</p></li>
<li><p>中心度分支用于预测每个像素点的中心度，表示该点是否接近目标的中心。</p></li>
<li><p>回归分支用于预测每个像素点到边界框边界的距离（即4D向量）。</p></li>
</ul>
</li>
</ol>
<p>图表右侧的插图展示了Head模块的详细结构：</p>
<ul class="simple">
<li><p>分类分支和中心度分支共享特征层。</p></li>
<li><p>回归分支独立处理特征层。</p></li>
<li><p>这些分支通过卷积操作生成最终的预测结果。</p></li>
</ul>
<p>总结：
FCOS的网络结构由主干网络、特征金字塔和Head模块组成。主干网络提取特征图，特征金字塔在不同尺度上生成特征层，Head模块通过分类、中心度和回归分支生成最终的检测结果。这个结构使得FCOS能够在不同尺度上进行目标检测，并且通过中心度分支提高了检测的准确性。</p>
<p>输入流程</p>
<ol class="arabic simple">
<li><p><strong>输入图像</strong>：</p>
<ul class="simple">
<li><p>输入图像的尺寸为 ( H \times W )（例如，800 x 1024）。</p></li>
<li><p>图像经过预处理（如归一化、尺寸调整等）后输入到网络中。</p></li>
</ul>
</li>
<li><p><strong>Backbone（主干网络）</strong>：</p>
<ul class="simple">
<li><p>输入图像首先通过主干网络（例如ResNet）进行特征提取。</p></li>
<li><p>主干网络生成多个特征图，分别为C3, C4, C5，这些特征图的尺寸分别为 ( H/8 \times W/8 ), ( H/16 \times W/16 ), ( H/32 \times W/32 )。</p></li>
</ul>
</li>
<li><p><strong>Feature Pyramid（特征金字塔）</strong>：</p>
<ul class="simple">
<li><p>特征金字塔网络（FPN）对C3, C4, C5特征图进行处理，生成P3, P4, P5, P6, P7特征层。</p></li>
<li><p>P3, P4, P5特征层通过上采样和融合操作生成，P6, P7特征层通过下采样操作生成。</p></li>
<li><p>这些特征层的尺寸分别为 ( H/8 \times W/8 ), ( H/16 \times W/16 ), ( H/32 \times W/32 ), ( H/64 \times W/64 ), ( H/128 \times W/128 )。</p></li>
</ul>
</li>
</ol>
<p>输出流程</p>
<ol class="arabic simple">
<li><p><strong>Head（头部模块）</strong>：</p>
<ul class="simple">
<li><p>每个特征层（P3到P7）都连接到一个Head模块。</p></li>
<li><p>Head模块包括三个分支：分类分支、中心度分支和回归分支。</p></li>
</ul>
</li>
<li><p><strong>分类分支</strong>：</p>
<ul class="simple">
<li><p>分类分支预测每个像素点的类别。</p></li>
<li><p>输出为每个特征层上每个像素点的类别概率。</p></li>
</ul>
</li>
<li><p><strong>中心度分支</strong>：</p>
<ul class="simple">
<li><p>中心度分支预测每个像素点的中心度，表示该点是否接近目标的中心。</p></li>
<li><p>输出为每个特征层上每个像素点的中心度得分。</p></li>
</ul>
</li>
<li><p><strong>回归分支</strong>：</p>
<ul class="simple">
<li><p>回归分支预测每个像素点到边界框边界的距离（即4D向量：l, t, r, b）。</p></li>
<li><p>输出为每个特征层上每个像素点的4D向量。</p></li>
</ul>
</li>
</ol>
<p>综合输出</p>
<ol class="arabic simple">
<li><p><strong>边界框生成</strong>：</p>
<ul class="simple">
<li><p>根据回归分支的输出（4D向量），计算每个像素点的边界框位置。</p></li>
<li><p>结合中心度得分和分类概率，筛选出高置信度的边界框。</p></li>
</ul>
</li>
<li><p><strong>非极大值抑制（NMS）</strong>：</p>
<ul class="simple">
<li><p>对生成的边界框进行非极大值抑制，去除重叠的边界框，保留最优的检测结果。</p></li>
</ul>
</li>
<li><p><strong>最终输出</strong>：</p>
<ul class="simple">
<li><p>输出最终的检测结果，包括目标的类别、边界框位置和置信度得分。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<p>FCOS的输入输出流程如下：</p>
<ol class="arabic simple">
<li><p>输入图像经过主干网络提取特征图。</p></li>
<li><p>特征图通过特征金字塔生成多尺度特征层。</p></li>
<li><p>每个特征层通过Head模块进行分类、中心度和回归预测。</p></li>
<li><p>根据回归分支的输出生成边界框，并结合分类和中心度得分筛选高置信度的边界框。</p></li>
<li><p>通过非极大值抑制去除重叠边界框，输出最终的检测结果。</p></li>
</ol>
<p>这个流程使得FCOS能够在不同尺度上进行目标检测，并且通过中心度分支提高了检测的准确性。</p>
<hr class="docutils" />
<img width="677" alt="fcos-fig3" src="https://github.com/isLinXu/issues/assets/59380685/b36e2be0-b02a-4873-8953-78ffacbc7ca7">
<p>图表展示了FCOS算法中的中心度（Center-ness）概念及其计算方法。中心度用于衡量一个像素点是否接近目标的中心，从而提高检测的准确性。</p>
<p>图表分析</p>
<ol class="arabic simple">
<li><p><strong>颜色表示</strong>：</p>
<ul class="simple">
<li><p>红色表示中心度为1，即像素点位于目标的中心。</p></li>
<li><p>蓝色表示中心度为0，即像素点远离目标的中心。</p></li>
<li><p>其他颜色表示中心度在0和1之间的值，颜色越接近红色，中心度越高；颜色越接近蓝色，中心度越低。</p></li>
</ul>
</li>
<li><p><strong>中心度计算</strong>：</p>
<ul class="simple">
<li><p>中心度通过公式（图中提到的Eq. (3)）计算。</p></li>
<li><p>公式的具体形式未在图中给出，但可以推测中心度是根据像素点到目标中心的距离进行衰减的。</p></li>
<li><p>当像素点位于目标中心时，中心度为1；当像素点远离目标中心时，中心度逐渐衰减到0。</p></li>
</ul>
</li>
<li><p><strong>中心度的作用</strong>：</p>
<ul class="simple">
<li><p>在测试阶段，网络预测的中心度与分类得分相乘。</p></li>
<li><p>这种操作可以降低那些由远离目标中心的像素点预测的低质量边界框的权重。</p></li>
<li><p>通过这种方式，中心度帮助网络更准确地定位目标，减少误检和漏检。</p></li>
</ul>
</li>
</ol>
<p>具体流程</p>
<ol class="arabic simple">
<li><p><strong>中心度预测</strong>：</p>
<ul class="simple">
<li><p>网络在每个像素点上预测中心度得分。</p></li>
<li><p>这些得分表示该像素点是否接近目标的中心。</p></li>
</ul>
</li>
<li><p><strong>中心度与分类得分相乘</strong>：</p>
<ul class="simple">
<li><p>在测试阶段，中心度得分与分类得分相乘。</p></li>
<li><p>这种操作可以有效地降低那些由远离目标中心的像素点预测的低质量边界框的权重。</p></li>
</ul>
</li>
<li><p><strong>边界框筛选</strong>：</p>
<ul class="simple">
<li><p>结合中心度和分类得分，筛选出高置信度的边界框。</p></li>
<li><p>通过这种方式，网络能够更准确地检测目标，并减少误检和漏检。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<p>图表展示了FCOS算法中的中心度概念及其计算方法。中心度用于衡量一个像素点是否接近目标的中心，从而提高检测的准确性。在测试阶段，中心度得分与分类得分相乘，可以有效地降低由远离目标中心的像素点预测的低质量边界框的权重。通过这种方式，FCOS能够更准确地定位目标，减少误检和漏检。</p>
<hr class="docutils" />
<img width="655" alt="fcos-fig4" src="https://github.com/isLinXu/issues/assets/59380685/970ca3af-db91-4227-9dc1-552508db6840">
<p>图表展示了在IOU（Intersection over Union）为0.50时，FCOS、原始RetinaNet和带有GN（Group Normalization）的RetinaNet的无类别区分的精确率-召回率（Precision-Recall）曲线。以下是对图表内容的分析和总结：</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>曲线说明</strong>：</p>
<ul class="simple">
<li><p><strong>蓝色曲线</strong>：表示FCOS的精确率-召回率曲线。</p></li>
<li><p><strong>橙色曲线</strong>：表示原始RetinaNet的精确率-召回率曲线。</p></li>
<li><p><strong>绿色曲线</strong>：表示带有GN的RetinaNet的精确率-召回率曲线。</p></li>
</ul>
</li>
<li><p><strong>精确率（Precision）</strong>：</p>
<ul class="simple">
<li><p>精确率表示在所有被预测为正样本的实例中，实际为正样本的比例。</p></li>
<li><p>精确率越高，表示误检（False Positive）越少。</p></li>
</ul>
</li>
<li><p><strong>召回率（Recall）</strong>：</p>
<ul class="simple">
<li><p>召回率表示在所有实际为正样本的实例中，被正确预测为正样本的比例。</p></li>
<li><p>召回率越高，表示漏检（False Negative）越少。</p></li>
</ul>
</li>
<li><p><strong>IOU = 0.50</strong>：</p>
<ul class="simple">
<li><p>IOU为0.50表示预测的边界框与真实边界框的重叠度达到50%时，认为检测是正确的。</p></li>
</ul>
</li>
</ol>
<p>分析</p>
<ol class="arabic simple">
<li><p><strong>FCOS vs. 原始RetinaNet</strong>：</p>
<ul class="simple">
<li><p>蓝色曲线（FCOS）在大部分召回率范围内都高于橙色曲线（原始RetinaNet），表示FCOS在相同召回率下具有更高的精确率。</p></li>
<li><p>这表明FCOS在减少误检方面表现更好。</p></li>
</ul>
</li>
<li><p><strong>FCOS vs. 带有GN的RetinaNet</strong>：</p>
<ul class="simple">
<li><p>蓝色曲线（FCOS）与绿色曲线（带有GN的RetinaNet）在大部分召回率范围内接近，但在某些区域FCOS略高。</p></li>
<li><p>这表明FCOS在某些情况下比带有GN的RetinaNet具有更高的精确率。</p></li>
</ul>
</li>
<li><p><strong>整体表现</strong>：</p>
<ul class="simple">
<li><p>三条曲线在召回率接近1时都迅速下降，表示在高召回率下，精确率会显著降低。</p></li>
<li><p>这是一种常见现象，因为在高召回率下，模型倾向于预测更多的正样本，从而增加误检。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<p>图表展示了在IOU为0.50时，FCOS、原始RetinaNet和带有GN的RetinaNet的无类别区分的精确率-召回率曲线。总体来看，FCOS在大部分召回率范围内表现优于原始RetinaNet和带有GN的RetinaNet，具有更高的精确率。这表明FCOS在减少误检方面表现更好，尤其是在中等召回率范围内。三种方法在高召回率下的精确率都显著下降，这是由于模型在高召回率下倾向于预测更多的正样本，从而增加误检。</p>
<hr class="docutils" />
<img width="678" alt="fcos-fig5" src="https://github.com/isLinXu/issues/assets/59380685/ce8f4695-397b-45c0-872a-b2a5235db26d">
<p>总结：</p>
<ol class="arabic simple">
<li><p><strong>FCOS</strong>：</p>
<ul class="simple">
<li><p>蓝色曲线表示FCOS方法的精度-召回关系。</p></li>
<li><p>在高召回率区域（接近1）时，精度略高于其他两种方法。</p></li>
</ul>
</li>
<li><p><strong>Original RetinaNet</strong>：</p>
<ul class="simple">
<li><p>橙色曲线表示原始RetinaNet方法的精度-召回关系。</p></li>
<li><p>在中等召回率区域（0.4到0.6）时，精度表现较好。</p></li>
</ul>
</li>
<li><p><strong>RetinaNet w/ GN</strong>：</p>
<ul class="simple">
<li><p>绿色曲线表示使用组归一化的RetinaNet方法的精度-召回关系。</p></li>
<li><p>整体曲线与原始RetinaNet相似，但在某些区域略有改进。</p></li>
</ul>
</li>
<li><p><strong>垂直虚线</strong>：</p>
<ul class="simple">
<li><p>在召回率为0.9的位置，三种方法的精度都接近0.2，表明在高召回率下，精度较低。</p></li>
</ul>
</li>
</ol>
<p>结论：</p>
<ul class="simple">
<li><p><strong>整体表现</strong>：三种方法的精度-召回曲线形状相似，表明它们在目标检测任务中的性能相近。</p></li>
<li><p><strong>FCOS优势</strong>：在高召回率区域，FCOS方法的精度略高于其他两种方法，表明其在检测更多正样本时具有一定优势。</p></li>
<li><p><strong>RetinaNet w/ GN改进</strong>：使用组归一化的RetinaNet方法在某些区域略有改进，但整体性能与原始RetinaNet相似。</p></li>
<li><p><strong>高召回率下的精度</strong>：在召回率为0.9时，三种方法的精度都较低，表明在追求高召回率时，精度会有所下降。</p></li>
</ul>
<p>总体而言，图表展示了三种目标检测方法在不同召回率下的精度表现，FCOS在高召回率区域表现略优，而使用组归一化的RetinaNet在某些区域有所改进。</p>
<hr class="docutils" />
<img width="664" alt="fcos-fig6" src="https://github.com/isLinXu/issues/assets/59380685/b339fa6e-5484-4a1c-8429-2b03153a06b2">
<p>总结：</p>
<ol class="arabic simple">
<li><p><strong>FCOS</strong>：</p>
<ul class="simple">
<li><p>蓝色曲线表示FCOS方法的精度-召回关系。</p></li>
<li><p>在低召回率区域（0到0.2）时，精度较高，但随着召回率增加，精度迅速下降。</p></li>
</ul>
</li>
<li><p><strong>Original RetinaNet</strong>：</p>
<ul class="simple">
<li><p>橙色曲线表示原始RetinaNet方法的精度-召回关系。</p></li>
<li><p>在低召回率区域（0到0.2）时，精度较高，且在中等召回率区域（0.2到0.4）时，精度下降较缓。</p></li>
</ul>
</li>
<li><p><strong>RetinaNet w/ GN</strong>：</p>
<ul class="simple">
<li><p>绿色曲线表示使用组归一化的RetinaNet方法的精度-召回关系。</p></li>
<li><p>整体曲线与原始RetinaNet相似，但在某些区域略有改进。</p></li>
</ul>
</li>
<li><p><strong>垂直虚线</strong>：</p>
<ul class="simple">
<li><p>在召回率为0.9的位置，三种方法的精度都接近0，表明在高召回率下，精度非常低。</p></li>
</ul>
</li>
</ol>
<p>结论：</p>
<ul class="simple">
<li><p><strong>整体表现</strong>：三种方法的精度-召回曲线形状相似，表明它们在目标检测任务中的性能相近。</p></li>
<li><p><strong>FCOS优势</strong>：在低召回率区域，FCOS方法的精度较高，但随着召回率增加，精度迅速下降。</p></li>
<li><p><strong>RetinaNet w/ GN改进</strong>：使用组归一化的RetinaNet方法在某些区域略有改进，但整体性能与原始RetinaNet相似。</p></li>
<li><p><strong>高召回率下的精度</strong>：在召回率为0.9时，三种方法的精度都非常低，表明在追求高召回率时，精度会显著下降。</p></li>
</ul>
<p>总体而言，图表展示了三种目标检测方法在不同召回率下的精度表现。FCOS在低召回率区域表现较优，而使用组归一化的RetinaNet在某些区域有所改进，但整体性能与原始RetinaNet相似。在高召回率下，三种方法的精度都较低，表明在高IOU阈值下，检测任务的难度较大。</p>
<hr class="docutils" />
<img width="1347" alt="fcos-fig7" src="https://github.com/isLinXu/issues/assets/59380685/92499493-79a9-49a1-bd7b-1280342b34f3">
总结：
<ol class="arabic simple">
<li><p><strong>左图（Without center-ness）</strong>：</p>
<ul class="simple">
<li><p>散点分布较为分散，许多点位于虚线的下方，表示这些检测框的分类得分高于其IOU得分。</p></li>
<li><p>这表明在不使用中心度的情况下，许多低质量的检测框（低IOU）仍然获得了较高的分类得分。</p></li>
</ul>
</li>
<li><p><strong>右图（With center-ness）</strong>：</p>
<ul class="simple">
<li><p>散点分布更加集中，尤其是在虚线的上方和附近。</p></li>
<li><p>许多低质量的检测框（低IOU）被推到了图的左侧，表示这些检测框的得分被显著降低。</p></li>
<li><p>这表明在使用中心度的情况下，低质量的检测框得分被有效抑制，高质量的检测框得分更为突出。</p></li>
</ul>
</li>
</ol>
<p>结论：</p>
<ul class="simple">
<li><p><strong>中心度的作用</strong>：中心度（center-ness）在目标检测任务中起到了显著的作用，通过将分类得分与中心度得分相乘，有效地降低了低质量检测框的得分。</p></li>
<li><p><strong>检测框质量提升</strong>：使用中心度后，检测框的质量得到了提升，高质量检测框（高IOU）的得分更加突出，低质量检测框的得分被显著抑制。</p></li>
<li><p><strong>评分分布变化</strong>：在不使用中心度的情况下，分类得分与IOU得分的关系较为分散，许多低质量检测框获得了较高的分类得分；而在使用中心度后，分类得分与IOU得分的关系更加集中，低质量检测框的得分被有效降低。</p></li>
</ul>
<p>总体而言，图表展示了中心度在目标检测任务中的重要性，通过使用中心度，可以显著提升检测框的质量，使得高质量检测框的得分更加突出，低质量检测框的得分被有效抑制。</p>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="FPN.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">FPN</p>
      </div>
    </a>
    <a class="right-next"
       href="SSD.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">SSD</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By isLinXu
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022, isLinXu.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>