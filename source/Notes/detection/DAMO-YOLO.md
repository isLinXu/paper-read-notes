# DAMO-YOLO

**标题：** DAMO-YOLO : A Report on Real-Time Object Detection Design

**作者：** Xianzhe Xu, Yiqi Jiang, Weihua Chen, Yilun Huang, Yuan Zhang, Xiuyu Sun (Alibaba Group)

**摘要：** 本文提出了一种快速且准确的目标检测方法DAMO-YOLO，该方法在性能上超越了现有的YOLO系列。DAMO-YOLO通过结合多种新技术进行扩展，包括神经架构搜索（NAS）、高效的重参数化广义特征金字塔网络（RepGFPN）、轻量级头部带有对齐的OTA标签分配，以及蒸馏增强技术。特别是，使用最大熵原则指导下的MAE-NAS方法搜索检测主干，以在低延迟和高性能的约束下产生具有空间金字塔池化和聚焦模块的ResNet-like/CSP-like结构。在设计颈部和头部时，遵循“大颈部，小头部”的规则。通过一系列实验验证了颈部和头部对检测性能的影响，并发现重颈部和单任务投影层可以产生更好的结果。此外，提出了AlignedOTA以解决标签分配中的错位问题，并引入了一种蒸馏方案以提高性能。基于这些新技术，构建了不同规模的模型套件，以满足不同场景的需求。

**1. 工作内容与动机：**
   - 提出了DAMO-YOLO，一种改进自YOLO的目标检测方法，旨在实现更快的速度和更高的准确性。
   - 动机是满足工业界对于实时约束下高性能目标检测方法的需求。

**2. 试图解决的问题：**
   - 如何在保持低延迟的同时提高目标检测的准确性。

**3. 是否是新问题：**
   - 不是新问题，但提出了新的解决方案。

**4. 科学假设：**
   - 通过集成NAS、RepGFPN、轻量级头部、AlignedOTA和蒸馏增强等技术，可以构建出性能更优的目标检测模型。

**5. 相关研究：**
   - 相关工作包括YOLO系列、YOLOX、PP-YOLOE等。
   - 归类为一阶段检测器、网络架构、训练策略。
   - 领域内值得关注的研究员包括YOLO系列的开发者和本文的作者。

**6. 解决方案的关键：**
   - MAE-NAS用于搜索检测主干。
   - RepGFPN用于融合多尺度特征。
   - ZeroHead设计用于减少计算量。
   - AlignedOTA用于改善标签分配。
   - 蒸馏增强用于提升小模型性能。

**7. 实验设计：**
   - 在COCO数据集上评估模型性能。
   - 使用T4-GPU和x86-CPU测试延迟。

**8. 数据集与代码开源：**
   - 使用COCO数据集进行定量评估。
   - 代码已在GitHub上开源。

**9. 实验结果与假设支持：**
   - 实验结果表明，DAMO-YOLO在COCO数据集上达到了43.6/47.7/50.2/51.9 mAPs，延迟为2.78/3.83/5.62/7.95 ms，支持了提出的科学假设。

**10. 论文贡献：**
   - 提出了DAMO-YOLO，一种新的高效目标检测方法。
   - 在公共COCO数据集上超越了现有的YOLO系列检测器。
   - 提供了不同规模的模型以支持不同的部署需求。

**11. 下一步工作：**
   - 进一步优化模型以适应更广泛的应用场景。
   - 探索更高效的网络结构和训练策略。
   - 在更大规模的数据集上进行训练和评估。

回答问题

1. **这篇论文做了什么工作，它的动机是什么？**
   - 论文提出了DAMO-YOLO，一种改进的实时目标检测方法，动机是提高目标检测的速度和准确性，以满足工业界的需求。

2. **这篇论文试图解决什么问题？**
   - 论文试图解决在保持低延迟的同时提高目标检测准确性的问题。

3. **这是否是一个新的问题？**
   - 不是新问题，但提出了新的解决方案。

4. **这篇文章要验证一个什么科学假设？**
   - 验证的科学假设是通过集成新技术可以构建出性能更优的目标检测模型。

5. **有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？**
   - 相关研究包括YOLO系列、YOLOX、PP-YOLOE等，归类为一阶段检测器、网络架构、训练策略。领域内值得关注的研究员包括YOLO系列的开发者和本文的作者。

6. **论文中提到的解决方案之关键是什么？**
   - 解决方案的关键是MAE-NAS、RepGFPN、ZeroHead、AlignedOTA和蒸馏增强技术。

7. **论文中的实验是如何设计的？**
   - 实验设计包括在COCO数据集上评估模型性能，并使用T4-GPU和x86-CPU测试延迟。

8. **用于定量评估的数据集上什么？代码有没有开源？**
   - 使用COCO数据集进行评估，代码已在GitHub上开源。

9. **论文中的实验及结果有没有很好地支持需要验证的科学假设？**
   - 是的，实验结果支持了提出的科学假设。

10. **这篇论文到底有什么贡献？**
    - 提出了DAMO-YOLO，一种新的高效目标检测方法，并在公共COCO数据集上超越了现有的YOLO系列检测器。

11. **下一步呢？有什么工作可以继续深入？**
    - 下一步工作可以包括进一步优化模型以适应更广泛的应用场景，探索更高效的网络结构和训练策略，以及在更大规模的数据集上进行训练和评估。


---

<img width="1037" alt="damo-yolo-fig1" src="https://github.com/isLinXu/issues/assets/59380685/dc844224-3900-4419-8749-4245e24fee39">

这张图展示了DAMO-YOLO与其他先进目标检测器在延迟和准确性之间的权衡。图表分为两个部分：(a) 在T4-GPU上的比较，(b) 在x86-CPU上的比较。以下是对图表的详细分析：

主要特点
- **延迟（Latency）**：表示模型处理一张图像所需的时间，延迟越低，模型越快。
- **mAP**：表示模型在COCO数据集上的平均精度，mAP越高，模型越准确。
- **权衡**：延迟和mAP之间的权衡，理想情况下，模型应具有较低的延迟和较高的mAP。

观察与分析
(a) T4-GPU上的比较
- **YOLOv5、YOLOv6、YOLOv7、YOLOv8、YOLOX**：这些模型在延迟和mAP之间表现出不同的权衡。总体上，随着延迟的增加，mAP也有所提高。
- **DAMO-YOLO（T/S/M/L）**：DAMO-YOLO的不同版本在延迟和mAP之间表现出较好的权衡。特别是DAMO-YOLO-L在较低延迟下达到了较高的mAP，显示出其在T4-GPU上的优越性能。

(b) x86-CPU上的比较
- **Nanodet-plus、YOLOv5-N、YOLOv6-N、YOLOv7-N、YOLOv8-N**：这些轻量级模型在延迟和mAP之间表现出不同的权衡。总体上，随着延迟的增加，mAP也有所提高。
- **DAMO-YOLO（N/Nm/Nl）**：DAMO-YOLO的轻量级版本在延迟和mAP之间表现出较好的权衡。特别是DAMO-YOLO-Nl在较低延迟下达到了较高的mAP，显示出其在x86-CPU上的优越性能。

结论
- **DAMO-YOLO**：在T4-GPU和x86-CPU上的表现均优于其他模型，显示出其在延迟和mAP之间的良好权衡。特别是DAMO-YOLO-L和DAMO-YOLO-Nl在各自平台上表现出色，具有较低的延迟和较高的mAP。
- **其他模型**：虽然其他模型在延迟和mAP之间也表现出一定的权衡，但总体上不如DAMO-YOLO的表现优越。

总结
这张图通过延迟和mAP的权衡展示了DAMO-YOLO与其他先进目标检测器在T4-GPU和x86-CPU上的性能比较。DAMO-YOLO在两个平台上均表现出色，显示出其在延迟和准确性之间的良好平衡，优于其他模型。通过这种比较，可以直观地评估不同模型在不同平台上的性能，从而选择最适合特定应用场景的模型。



---
<img width="1059" alt="damo-yolo-fig2" src="https://github.com/isLinXu/issues/assets/59380685/5d8557e7-c573-4ab7-acff-7a4155a6d7e2">

这张图展示了MAE-NAS（Model Architecture Evolution - Neural Architecture Search）中使用的三种不同的基本构建块（building block），分别是MobBlock、ResBlock和CSPBlock。以下是对图表的详细分析：

图表内容

 (a) MobBlock
- **结构**：MobBlock是MobileNetV3块的变体，作为DAMO-YOLO轻量级模型的基本构建块。
- **组件**：
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
  - **Conv, K=3, G=N**：3x3卷积，组数为N。
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
- **特点**：MobBlock通过深度可分离卷积（Depthwise Separable Convolution）来减少计算量和参数量，适用于轻量级模型。

(b) ResBlock
- **结构**：ResBlock源自ResNet，DAMO-YOLO-S和DAMO-YOLO-T基于此构建。
- **组件**：
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
  - **Conv, K=3, G=1**：3x3卷积，组数为1。
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
- **特点**：ResBlock通过残差连接（Residual Connection）来缓解深层网络中的梯度消失问题，适用于中等复杂度的模型。

(c) CSPBlock
- **结构**：CSPBlock源自CSPNet，由于其在深度网络中的优异表现，被用作DAMO-YOLO-M和DAMO-YOLO-L模型的基本构建块。
- **组件**：
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
  - **Conv, K=3, G=1**：3x3卷积，组数为1。
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
  - **Conv, K=3, G=1**：3x3卷积，组数为1。
  - **Conv, K=1, G=1**：1x1卷积，组数为1。
- **特点**：CSPBlock通过跨阶段部分网络（Cross Stage Partial Network）来分割特征图并融合，减少计算量和内存使用，同时提高模型的表示能力，适用于高复杂度的模型。

主要特点
- **MobBlock**：适用于轻量级模型，通过深度可分离卷积减少计算量和参数量。
- **ResBlock**：适用于中等复杂度的模型，通过残差连接缓解梯度消失问题。
- **CSPBlock**：适用于高复杂度的模型，通过跨阶段部分网络提高表示能力并减少计算量和内存使用。

结论
- **MobBlock**：适用于需要高效计算和低参数量的轻量级模型，如DAMO-YOLO轻量级模型。
- **ResBlock**：适用于需要平衡计算效率和模型复杂度的中等复杂度模型，如DAMO-YOLO-S和DAMO-YOLO-T。
- **CSPBlock**：适用于需要高表示能力和高性能的复杂模型，如DAMO-YOLO-M和DAMO-YOLO-L。

总结
这张图展示了MAE-NAS中使用的三种不同的基本构建块（MobBlock、ResBlock和CSPBlock）的结构和特点。每种构建块适用于不同复杂度的模型，通过选择合适的构建块，可以在计算效率和模型性能之间取得良好的平衡。MobBlock适用于轻量级模型，ResBlock适用于中等复杂度模型，而CSPBlock适用于高复杂度模型。通过这种方式，MAE-NAS能够灵活地构建适应不同需求的目标检测模型。


---
<img width="731" alt="damo-yolo-fig3" src="https://github.com/isLinXu/issues/assets/59380685/8f24df7e-e0c2-495d-801a-4382154d0366">

这张图展示了DAMO-YOLO的网络架构，包括其主要组件和数据流。以下是对图表的详细分析：

1. Backbone（主干网络）
- **MAE-NAS**：使用MAE-NAS（Model Architecture Evolution - Neural Architecture Search）作为主干网络，用于提取多尺度特征图。
- **功能**：从输入图像中提取多尺度特征图，为后续的特征融合和任务投影提供基础。

2. Efficient RepGFPN（高效特征金字塔网络）

- **F Fusion Block**：特征融合块，用于融合高层语义特征和低层空间特征。
    - **结构**：
        - **1x1卷积**：用于调整通道数。
        - **Simplify Rep 3x3**：简化的Rep 3x3模块，用于特征提取和融合。
        - **1x1卷积**：用于进一步调整通道数。
    - **Simplify Rep 3x3**：简化的Rep 3x3模块，包含两个3x3卷积层、批归一化（BN）和激活函数（Act），用于训练和推理。
- **功能**：高效的特征金字塔网络，用于细化和融合高层语义特征和低层空间特征。

3. Zero Head（零头部）

- **任务投影层**：每个任务（分类和回归）包含一个任务投影层。
    - **cls**：分类任务投影层。
    - **reg**：回归任务投影层。
- **功能**：仅包含任务投影层，用于将融合后的特征映射到具体的任务输出（分类和回归）。

数据流
1. **输入图像**：通过MAE-NAS主干网络提取多尺度特征图。
2. **特征融合**：通过Efficient RepGFPN中的F Fusion Block进行特征融合，细化和融合高层语义特征和低层空间特征。
3. **任务投影**：通过Zero Head中的任务投影层，将融合后的特征映射到具体的任务输出（分类和回归）。

主要特点
- **MAE-NAS**：作为主干网络，提供多尺度特征图。
- **Efficient RepGFPN**：高效的特征金字塔网络，通过F Fusion Block进行特征融合和细化。
- **Zero Head**：简化的头部结构，仅包含任务投影层，用于分类和回归任务。

结论

- **高效性**：DAMO-YOLO通过使用MAE-NAS主干网络和Efficient RepGFPN，实现了高效的特征提取和融合。
- **简化结构**：Zero Head的设计简化了头部结构，仅包含任务投影层，减少了计算复杂度。
- **多任务处理**：通过任务投影层，DAMO-YOLO能够同时处理分类和回归任务，适用于目标检测任务。

总结

这张图展示了DAMO-YOLO的网络架构，包括MAE-NAS主干网络、Efficient RepGFPN和Zero Head。MAE-NAS用于提取多尺度特征图，Efficient RepGFPN通过F Fusion Block进行特征融合和细化，Zero Head通过任务投影层将融合后的特征映射到具体的任务输出。通过这种设计，DAMO-YOLO实现了高效的特征提取和融合，简化了头部结构，并能够同时处理分类和回归任务。

---

<img width="666" alt="damo-yolo-fig4" src="https://github.com/isLinXu/issues/assets/59380685/fc8ebf93-c07f-4735-a286-7da7e0ad0dde">

这张图展示了在不同蒸馏损失权重（distillation loss weight）下，分类损失（classification loss）和准确率（accuracy）的变化曲线。蒸馏损失权重分别设置为0.5、2和10。以下是对图表的详细分析：
主要观察

1. **分类损失（classification loss）**：
    - **蒸馏损失权重为0.5（蓝色虚线）**：分类损失快速收敛，并且在整个训练过程中保持在较低水平。
    - **蒸馏损失权重为2（绿色虚线）**：分类损失在初期波动较大，但逐渐收敛。
    - **蒸馏损失权重为10（红色虚线）**：分类损失在整个训练过程中波动较大，收敛速度较慢。
2. **准确率（accuracy）**：
    - **蒸馏损失权重为0.5（蓝色实线）**：准确率快速上升，并在整个训练过程中保持在较高水平。
    - **蒸馏损失权重为2（绿色实线）**：准确率在初期波动较大，但逐渐上升并趋于稳定。
    - **蒸馏损失权重为10（红色实线）**：准确率在整个训练过程中波动较大，最终准确率较低。

结论
- **蒸馏损失权重为0.5**：分类损失快速收敛，准确率快速上升并保持在较高水平，表现最佳。
- **蒸馏损失权重为2**：分类损失和准确率在初期波动较大，但最终趋于稳定，表现中等。
- **蒸馏损失权重为10**：分类损失和准确率在整个训练过程中波动较大，最终准确率较低，表现最差。

总结
这张图展示了在不同蒸馏损失权重下，分类损失和准确率的变化情况。结果表明，当蒸馏损失权重设置为0.5时，分类损失收敛最快，准确率最高，表现最佳。较高的蒸馏损失权重（如2和10）会导致分类损失和准确率的波动较大，收敛速度较慢，最终准确率较低。因此，选择合适的蒸馏损失权重对于模型的快速收敛和高准确率至关重要。