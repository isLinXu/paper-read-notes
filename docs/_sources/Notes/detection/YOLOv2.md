# YOLOv2

**标题：** YOLO9000: Better, Faster, Stronger

**作者：** Joseph Redmon, Ali Farhadi

**单位：** University of Washington, Allen Institute for AI

**网址：** http://pjreddie.com/yolo9000/

**摘要：**
本文介绍了YOLO9000，一个先进的实时目标检测系统，能够检测超过9000个对象类别。首先，作者提出了对YOLO检测方法的各种改进，包括新颖的和借鉴以往工作的改进。改进后的模型，YOLOv2，在标准的检测任务上如PASCAL VOC和COCO达到了最先进的水平。使用一种新颖的多尺度训练方法，同一个YOLOv2模型可以在不同尺寸下运行，提供了在速度和准确性之间的简单权衡。在67 FPS下，YOLOv2在VOC 2007上达到了76.8 mAP。在40 FPS下，YOLOv2达到了78.6 mAP，超过了如Faster RCNN和SSD等最先进的方法，同时运行速度仍然显著更快。最后，作者提出了一种在目标检测和分类上联合训练的方法。使用这种方法，作者同时在COCO检测数据集和ImageNet分类数据集上训练了YOLO9000。这种联合训练允许YOLO9000预测那些没有标记检测数据的对象类别的检测。作者在ImageNet检测任务上验证了他们的方法，YOLO9000在ImageNet检测验证集上达到了19.7 mAP，尽管只有200个类别中的44个有检测数据。在COCO之外的156个类别上，YOLO9000达到了16.0 mAP。但YOLO能检测的不仅仅是200个类别；它预测了超过9000个不同对象类别的检测，并且仍然实时运行。

**1、这篇论文试图解决的问题：**
论文试图解决的问题是提高目标检测系统的速度、准确性，并扩大其能够检测的对象类别数量。具体来说，作者想要改进YOLO（You Only Look Once）目标检测系统，使其能够实时检测更多的对象类别，同时保持或提高准确性和速度。

**2、这是否是一个新的问题：**
这不是一个全新的问题，因为目标检测是计算机视觉领域的一个长期存在的研究问题。然而，作者在现有基础上提出了新的改进和方法，使得YOLO系统能够检测更多的类别，并且在速度和准确性上有所提升。

**3、这篇文章要验证的科学假设：**
文章的核心科学假设是，通过提出的方法改进，YOLO系统能够在保持实时性能的同时，提高检测的准确性，并且能够扩展到检测更多的对象类别。

**4、有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？**
相关研究包括但不限于：
- R-CNN系列：Region-based Convolutional Neural Networks，包括Fast R-CNN、Faster R-CNN等。
- SSD：Single Shot MultiBox Detector。
- 其他实时目标检测系统。
这些研究可以归类为计算机视觉中的目标检测领域。领域内值得关注的研究员包括但不限于Joseph Redmon、Ali Farhadi、Ross Girshick等。

**5、论文中提到的解决方案之关键是什么：**
解决方案的关键包括：
- 对YOLO检测方法的多项改进，如批归一化、高分辨率分类器、使用锚框、通过k-means确定锚框尺寸等。
- 多尺度训练方法，允许模型在不同尺寸下运行。
- 联合训练目标检测和分类数据集，使用WordTree结构来整合不同数据集的类别标签。

**6、论文中的实验是如何设计的：**
实验设计包括在标准的检测任务上评估YOLOv2的性能，如PASCAL VOC和COCO数据集，并与当时的最先进方法进行比较。此外，还包括使用COCO检测数据集和ImageNet分类数据集来训练YOLO9000，并在ImageNet检测任务上进行评估。

**7、用于定量评估的数据集上什么？代码有没有开源？**
用于定量评估的数据集包括PASCAL VOC 2007、COCO test-dev2015和ImageNet检测验证集。代码和预训练模型已经在论文提供的网址上开源。

**8、论文中的实验及结果有没有很好地支持需要验证的科学假设？**
是的，实验结果支持了作者的科学假设。YOLOv2在多个数据集上达到了最先进的性能，同时在不同FPS下保持了高mAP，证明了其速度和准确性的提升。YOLO9000在没有检测数据的类别上也表现出了良好的性能，证明了其能够通过联合训练检测更多类别的能力。

**9、这篇论文到底有什么贡献？**
论文的贡献包括：
- 提出了改进的YOLOv2模型，该模型在多个数据集上达到了最先进的性能。
- 引入了多尺度训练方法，提高了模型的灵活性。
- 提出了一种联合训练目标检测和分类数据集的方法，显著扩展了检测系统能够识别的类别数量。
- 开源了代码和预训练模型，促进了研究社区的进一步研究。

**10、下一步呢？有什么工作可以继续深入？**
下一步的工作可能包括：
- 探索更强大的模型架构来进一步提升检测性能。
- 研究更精细的标签分配策略，以改善在训练期间对分类数据的弱监督。
- 将这些技术应用于其他视觉任务，如图像分割。
- 使用这些技术来处理不同来源和结构的数据，以构建更强大的视觉世界模型。