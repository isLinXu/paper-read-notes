## 注意力部分(attention)

| Num  | Title                                                        | Field | Desc                     | Author | Time | read |
| ---- | ------------------------------------------------------------ | ----- | ------------------------ | ------ | ---- | ---- |
| 1    | Attention-Based Models for Speech Recognition                |       | 混合注意力机制论文       |        | 2015 |      |
| 2    | Effective Approaches to Attention-based Neural Machine Translation |       | 孪生注意力论文           |        | 2015 |      |
| 3    | Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks |       | 各自升级的孪生注意力论文 |        | 2016 |      |
| 4    | NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE |       | 孪生注意力论文           |        | 2016 |      |
| 5    | Attention Is All You Need                                    |       | 大道至简的注意力论文     |        | 2017 |      |
| 6    | Online and Linear-Time Attention by Enforcing Monotonic Alignments |       | 单调注意力机制论文       |        | 2017 |      |
|      |                                                              |       |                          |        |      |      |
|      |                                                              |       |                          |        |      |      |

## 