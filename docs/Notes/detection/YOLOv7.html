
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>YOLOv7 &#8212; 论文阅读笔记</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css?v=7f9a90b1" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=40d2fe7a"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Notes/detection/YOLOv7';</script>
    <link rel="icon" href="../../_static/panda.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="DY-yolov7" href="Dy-yolov7.html" />
    <link rel="prev" title="YOLOS" href="YOLOS.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="论文阅读笔记 - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="论文阅读笔记 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Method/index.html">论文阅读指南</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Method/efficent_read_paper.html">高效阅读方法及流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/how_to_read_paper.html">如何阅读论文</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/paper_10_question.html">论文速读十问</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/read_important_tips.html">读论文与口头报告的几项重点</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/reference.html">参考材料</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../List/index.html">论文阅读清单</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../List/basis.html">神经网络基础(basis)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/attention.html">注意力部分(attention)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/batch_normalization.html">批量&amp;正则化(batch&amp;normalization)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/classification.html">图像分类(CLAS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/convolutional.html">高级卷积网络知识(Convolutional)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/gan.html">AI合成部分(GAN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/nlp.html">自然语言处理(NLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/objectdetection.html">目标检测(OBJ)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/rnn.html">循环神经网络(RNN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/segementation.html">目标分割(SEG)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/transformer.html">Transformer</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/multimodal.html">多模态(MultiModal Learning)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/llm.html">大语言模型(Large Language Models)</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">论文阅读笔记</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../mm-l/index.html">多模态(MultiModal Machine Learning)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mm-l/blip-v1.html">BLIP: Bootstrapping Language-Image Pre-training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mm-l/blip-v2.html">BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../llm/index.html">大语言模型(Large Language Models)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../llm/opt.html">OPT: OPT : Open Pre-trained Transformer Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v1.html">GPT-v1:Improving Language Understanding by Generative Pre-Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v2.html">GPT-v2:Language Models are Unsupervised Multitask Learners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v3.html">GPT-v3:Language Models are Few-Shot Learners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v4.html">GPT-v4:GPT-4 Technical Report</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">detection</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="survey_all.html">survey_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="RCNN.html">RCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Fast%20R-CNN.html">Fast R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Faster%20R-CNN.html">Faster R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mask%20R-CNN.html">Mask R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="FCN.html">FCN</a></li>
<li class="toctree-l3"><a class="reference internal" href="FPN.html">FPN</a></li>
<li class="toctree-l3"><a class="reference internal" href="SSD.html">SSD</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mobilenet-SSDv2.html">Mobilenet-SSDv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mask%20R-CNN.html">Mask R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Cascade-RCNN.html">Cascade-RCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="RetinaNet.html">RetinaNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv1.html">YOLOv1</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv2.html">YOLOv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv3.html">YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv4.html">YOLOv4</a></li>
<li class="toctree-l3"><a class="reference internal" href="Scaled-YOLOv4.html">Scaled-YOLOv4</a></li>
<li class="toctree-l3"><a class="reference internal" href="ASFF.html">ASFF</a></li>
<li class="toctree-l3"><a class="reference internal" href="ATSS.html">ATSS</a></li>
<li class="toctree-l3"><a class="reference internal" href="SABL.html">SABL</a></li>
<li class="toctree-l3"><a class="reference internal" href="SM-NAS.html">SM-NAS</a></li>
<li class="toctree-l3"><a class="reference internal" href="TSD.html">TSD</a></li>
<li class="toctree-l3"><a class="reference internal" href="RDSNet.html">RDSNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="CenterMask.html">CenterMask</a></li>
<li class="toctree-l3"><a class="reference internal" href="Simple%20Multi-dataset%20Detection.html">Simple Multi-dataset Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOX.html">YOLOX</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv6.html">YOLOv6</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOv1.html">PP-YOLOv1</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOv2.html">PP-YOLOv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOF.html">YOLOF</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOP.html">YOLOP</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOR.html">YOLOR</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOS.html">YOLOS</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">YOLOv7</a></li>
<li class="toctree-l3"><a class="reference internal" href="Dy-yolov7.html">DY-yolov7</a></li>
<li class="toctree-l3"><a class="reference internal" href="Gold-YOLO.html">Gold-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv6_v3.0.html">YOLOv6</a></li>
<li class="toctree-l3"><a class="reference internal" href="DAMO-YOLO.html">DAMO-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="ViT-YOLO.html">ViT-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLO-MS.html">YOLO-MS</a></li>
<li class="toctree-l3"><a class="reference internal" href="RT-DETR.html">RT-DETR</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv9.html">YOLOv9</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOOC.html">YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel Class Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="OWL-ViT.html">OWL-ViT</a></li>
<li class="toctree-l3"><a class="reference internal" href="OWLv2.html">OWLv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="RTMDet.html">RTMDet</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLO-World.html">YOLO-World</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOOC.html">YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel Class Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="MDETR.html">MDETR</a></li>
<li class="toctree-l3"><a class="reference internal" href="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B020%E5%B9%B4.html"><strong>目标检测二十年：一项综述</strong></a></li>





<li class="toctree-l3"><a class="reference internal" href="yolo%E7%BB%BC%E8%BF%B0.html"><strong>YOLO的全面综述：从YOLOv1到YOLOv8及未来</strong></a></li>




















</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Read/index.html">论文阅读记录</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Summary/index.html">论文阅读总结</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes/edit/main/Notes/detection/YOLOv7.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes/issues/new?title=Issue%20on%20page%20%2FNotes/detection/YOLOv7.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/Notes/detection/YOLOv7.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>YOLOv7</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="yolov7">
<h1>YOLOv7<a class="headerlink" href="#yolov7" title="Link to this heading">#</a></h1>
<p><strong>标题：</strong> YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</p>
<p><strong>作者：</strong> Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao (Institute of Information Science, Academia Sinica, Taiwan)</p>
<p><strong>摘要：</strong>
YOLOv7在实时目标检测领域中超越了所有已知的目标检测器，无论是在速度还是准确性方面。在GPU V100上，YOLOv7-E6目标检测器（56 FPS, 55.9% AP）在速度上比基于变换器的检测器SWINL Cascade-Mask R-CNN（9.2 FPS, 53.9% AP）快509%，准确性上高出2%，比基于卷积的检测器ConvNeXt-XL Cascade-Mask R-CNN（8.6 FPS, 55.2% AP）快551%，准确性上高出0.7%。</p>
<p><strong>1. 问题：</strong>
论文试图解决实时目标检测中速度与准确性之间的权衡问题，提高目标检测器在不同设备上的运行效率和准确性。</p>
<p><strong>2. 新问题：</strong>
这不是一个全新的问题，但是YOLOv7提出了新的解决方案，以实现更好的速度和准确性权衡。</p>
<p><strong>3. 科学假设：</strong>
假设通过优化训练过程和模型架构，可以实现不增加推理成本的情况下提高目标检测的准确性。</p>
<p><strong>4. 相关研究：</strong></p>
<ul class="simple">
<li><p>实时目标检测器：YOLO系列、FCOS、SSD、RetinaNet等。</p></li>
<li><p>模型重参数化和动态标签分配：与网络训练和目标检测相关的方法。</p></li>
<li><p>领域内值得关注的研究员包括但不限于：Joseph Redmon、Ali Farhadi（YOLO系列的主要贡献者）。</p></li>
</ul>
<p><strong>5. 解决方案关键：</strong></p>
<ul class="simple">
<li><p>设计了可训练的“免费功能包”（trainable bag-of-freebies），包括新的优化模块和方法。</p></li>
<li><p>提出了“计划重参数化模型”（planned re-parameterized model）和“粗到细引导标签分配”（coarse-to-fine lead guided label assignment）方法。</p></li>
</ul>
<p><strong>6. 实验设计：</strong>
实验使用Microsoft COCO数据集进行，所有模型从头开始训练，不使用预训练模型。设计了针对边缘GPU、常规GPU和云GPU的基本模型，并使用提出的复合缩放方法对模型进行扩展。</p>
<p><strong>7. 数据集与代码：</strong>
使用的数据集是COCO，源代码已在GitHub上开源：https://github.com/WongKinYiu/yolov7。</p>
<p><strong>8. 实验结果：</strong>
实验结果表明，YOLOv7在不同模型尺寸上均取得了优异的性能，支持了论文提出的科学假设。</p>
<p><strong>9. 贡献：</strong></p>
<ul class="simple">
<li><p>提出了YOLOv7，一个高性能的实时目标检测模型。</p></li>
<li><p>引入了新的训练方法和模型优化技术，提高了目标检测的准确性和速度。</p></li>
<li><p>提供了不同规模的模型以适应不同的计算设备。</p></li>
</ul>
<p><strong>10. 下一步工作：</strong></p>
<ul class="simple">
<li><p>进一步探索和优化YOLOv7模型，以提高对小目标的检测能力。</p></li>
<li><p>在更多的数据集上测试YOLOv7的性能。</p></li>
<li><p>探索YOLOv7在不同应用场景中的实用性和效果。</p></li>
</ul>
<p>回答问题</p>
<ol class="arabic simple">
<li><p><strong>问题：</strong> 提高实时目标检测的速度和准确性。</p></li>
<li><p><strong>新问题：</strong> 不是新问题，但提出了新的解决方案。</p></li>
<li><p><strong>科学假设：</strong> 通过训练过程和模型架构的优化，可以在不增加推理成本的情况下提高检测准确性。</p></li>
<li><p><strong>相关研究：</strong> YOLO系列、FCOS、SSD、RetinaNet等。</p></li>
<li><p><strong>解决方案关键：</strong> 可训练的“免费功能包”，计划重参数化模型，粗到细引导标签分配。</p></li>
<li><p><strong>实验设计：</strong> 在COCO数据集上进行，设计了不同规模的模型。</p></li>
<li><p><strong>数据集与代码：</strong> 使用COCO数据集，代码已开源。</p></li>
<li><p><strong>实验结果：</strong> 支持假设，YOLOv7在不同模型尺寸上均取得了优异性能。</p></li>
<li><p><strong>贡献：</strong> 提出了YOLOv7和一系列新的训练和模型优化技术。</p></li>
<li><p><strong>下一步工作：</strong> 提高小目标检测能力，测试更多数据集，探索应用场景。</p></li>
</ol>
<hr class="docutils" />
<p>总结</p>
<ul class="simple">
<li><p><strong>YOLOv7的优势</strong>：</p>
<ul>
<li><p>YOLOv7在推理时间和平均精度上均表现出色，推理时间最短，平均精度最高。</p></li>
<li><p>YOLOv7比其他模型快120%，在实时目标检测任务中具有显著优势。</p></li>
</ul>
</li>
<li><p><strong>其他模型的表现</strong>：</p>
<ul>
<li><p>YOLO-R和PPYOLOE在推理时间和平均精度上次于YOLOv7，但仍表现良好。</p></li>
<li><p>YOLOX和Scaled-YOLOv4的推理时间较长，平均精度较低。</p></li>
<li><p>YOLOv5的推理时间最长，平均精度最低，表现最差。</p></li>
</ul>
</li>
</ul>
<p>结论</p>
<p>通过对YOLOv7与其他模型在MS COCO数据集上的性能对比，可以看出YOLOv7在推理时间和平均精度上均表现出色，具有显著的优势。YOLOv7在实时目标检测任务中具有更高的效率和准确性，是当前最先进的目标检测模型之一。根据具体应用场景的需求，可以选择合适的模型进行目标检测任务。</p>
<hr class="docutils" />
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>VoVNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含多个3x3卷积层和1x1卷积层。</p></li>
<li><p>特点：使用层聚合策略，通过多个卷积层的堆叠来提取特征。</p></li>
</ul>
</li>
<li><p><strong>CSPVoVNet</strong>：</p>
<ul class="simple">
<li><p>结构：在VoVNet的基础上增加了部分卷积层（partial convolution）。</p></li>
<li><p>特点：通过部分卷积层的引入，进一步提高特征提取的效率。</p></li>
</ul>
</li>
<li><p><strong>ELAN</strong>：</p>
<ul class="simple">
<li><p>结构：包含多个3x3卷积层和1x1卷积层，并引入了堆叠和计算块（stack &amp; computational block）。</p></li>
<li><p>特点：通过堆叠和计算块的引入，增强了特征提取的能力。</p></li>
</ul>
</li>
<li><p><strong>E-ELAN</strong>：</p>
<ul class="simple">
<li><p>结构：在ELAN的基础上增加了扩展基数（expand cardinality）和混洗基数（shuffle cardinality）。</p></li>
<li><p>特点：通过扩展和混洗基数，进一步增强了特征提取的能力，并提高了参数和计算的使用效率。</p></li>
</ul>
</li>
</ol>
<p>输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像通过输入层进入模型。</p></li>
<li><p>输入层通常是一个卷积层，用于初步提取图像的低级特征。</p></li>
</ul>
</li>
<li><p><strong>特征提取</strong>：</p>
<ul class="simple">
<li><p><strong>VoVNet</strong>：输入图像通过多个3x3卷积层和1x1卷积层进行特征提取。每个卷积层提取不同层次的特征，并通过层聚合策略进行组合。</p></li>
<li><p><strong>CSPVoVNet</strong>：在VoVNet的基础上，部分卷积层（partial convolution）进一步提取特征，提高特征提取的效率。</p></li>
<li><p><strong>ELAN</strong>：输入图像通过多个3x3卷积层和1x1卷积层进行特征提取，并通过堆叠和计算块（stack &amp; computational block）增强特征提取能力。</p></li>
<li><p><strong>E-ELAN</strong>：在ELAN的基础上，扩展基数（expand cardinality）和混洗基数（shuffle cardinality）进一步增强特征提取能力，并提高参数和计算的使用效率。</p></li>
</ul>
</li>
<li><p><strong>特征聚合</strong>：</p>
<ul class="simple">
<li><p><strong>VoVNet</strong>：通过层聚合策略，将不同卷积层提取的特征进行组合。</p></li>
<li><p><strong>CSPVoVNet</strong>：通过部分卷积层的引入，进一步聚合特征。</p></li>
<li><p><strong>ELAN</strong>：通过堆叠和计算块，将不同卷积层提取的特征进行组合。</p></li>
<li><p><strong>E-ELAN</strong>：通过扩展和混洗基数，将不同卷积层提取的特征进行组合，增强特征聚合能力。</p></li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终的特征通过输出层进行处理，生成目标检测结果。</p></li>
<li><p>输出层通常是一个全连接层或卷积层，用于生成目标检测的类别和位置。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>VoVNet</strong>：通过层聚合策略，提取和组合不同层次的特征。</p></li>
<li><p><strong>CSPVoVNet</strong>：在VoVNet的基础上，通过部分卷积层进一步提高特征提取效率。</p></li>
<li><p><strong>ELAN</strong>：通过堆叠和计算块，增强特征提取能力。</p></li>
<li><p><strong>E-ELAN</strong>：在ELAN的基础上，通过扩展和混洗基数，进一步增强特征提取能力，并提高参数和计算的使用效率。</p></li>
</ul>
<p>结论</p>
<p>通过对四种模型结构的分析，可以看出每种模型在特征提取和聚合方面都有其独特的策略和优势。E-ELAN在ELAN的基础上，通过扩展和混洗基数，进一步增强了特征提取能力，并提高了参数和计算的使用效率，是当前最先进的特征提取模型之一。根据具体应用场景的需求，可以选择合适的模型进行目标检测任务。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>基于连接的模型（concatenation-based model）</strong>：</p>
<ul class="simple">
<li><p>结构：包含多个卷积层，通过连接操作将特征进行组合。</p></li>
<li><p>特点：通过连接操作，将不同卷积层提取的特征进行组合，形成更丰富的特征表示。</p></li>
</ul>
</li>
<li><p><strong>深度扩展的基于连接的模型（scaled-up concatenation-based model）</strong>：</p>
<ul class="simple">
<li><p>结构：在基于连接的模型基础上，通过增加卷积层的深度进行扩展。</p></li>
<li><p>特点：通过增加卷积层的深度，进一步提取更深层次的特征。</p></li>
</ul>
</li>
<li><p><strong>复合扩展的基于连接的模型（compound scaling up depth and width for concatenation-based model）</strong>：</p>
<ul class="simple">
<li><p>结构：在深度扩展的基础上，同时对深度和宽度进行扩展。</p></li>
<li><p>特点：通过同时扩展深度和宽度，增强特征提取能力，并提高模型的性能。</p></li>
</ul>
</li>
</ol>
<p>输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像通过输入层进入模型。</p></li>
<li><p>输入层通常是一个卷积层，用于初步提取图像的低级特征。</p></li>
</ul>
</li>
<li><p><strong>特征提取</strong>：</p>
<ul class="simple">
<li><p><strong>基于连接的模型</strong>：</p>
<ul>
<li><p>输入图像通过多个卷积层进行特征提取。</p></li>
<li><p>每个卷积层提取不同层次的特征，并通过连接操作将这些特征进行组合。</p></li>
</ul>
</li>
<li><p><strong>深度扩展的基于连接的模型</strong>：</p>
<ul>
<li><p>在基于连接的模型基础上，通过增加卷积层的深度，进一步提取更深层次的特征。</p></li>
<li><p>连接操作将不同深度的特征进行组合，形成更丰富的特征表示。</p></li>
</ul>
</li>
<li><p><strong>复合扩展的基于连接的模型</strong>：</p>
<ul>
<li><p>在深度扩展的基础上，同时对深度和宽度进行扩展。</p></li>
<li><p>通过增加卷积层的深度和宽度，增强特征提取能力。</p></li>
<li><p>连接操作将不同深度和宽度的特征进行组合，形成更强大的特征表示。</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>特征聚合</strong>：</p>
<ul class="simple">
<li><p><strong>基于连接的模型</strong>：通过连接操作，将不同卷积层提取的特征进行组合。</p></li>
<li><p><strong>深度扩展的基于连接的模型</strong>：通过增加卷积层的深度，进一步聚合特征。</p></li>
<li><p><strong>复合扩展的基于连接的模型</strong>：通过同时扩展深度和宽度，进一步增强特征聚合能力。</p></li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终的特征通过输出层进行处理，生成目标检测结果。</p></li>
<li><p>输出层通常是一个全连接层或卷积层，用于生成目标检测的类别和位置。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>基于连接的模型</strong>：通过连接操作，将不同卷积层提取的特征进行组合，形成更丰富的特征表示。</p></li>
<li><p><strong>深度扩展的基于连接的模型</strong>：在基于连接的模型基础上，通过增加卷积层的深度，进一步提取更深层次的特征。</p></li>
<li><p><strong>复合扩展的基于连接的模型</strong>：在深度扩展的基础上，同时对深度和宽度进行扩展，增强特征提取能力，并提高模型的性能。</p></li>
</ul>
<p>结论</p>
<p>通过对三种模型结构的分析，可以看出每种模型在特征提取和聚合方面都有其独特的策略和优势。复合扩展的基于连接的模型通过同时扩展深度和宽度，进一步增强了特征提取能力，并提高了模型的性能，是当前最先进的特征提取模型之一。根据具体应用场景的需求，可以选择合适的模型进行目标检测任务。</p>
<hr class="docutils" />
<p>图表展示了几种不同的模型结构：PlainNet、RepPlainNet、ResNet、RepResNet、P1-RepResNet、P2-RepResNet、P3-RepResNet和P4-RepResNet。每种模型结构都采用了不同的卷积和连接方法，以提高模型的性能。以下是对图表内容的详细分析和总结。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>PlainNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含两个3x3卷积层。</p></li>
<li><p>特点：简单的卷积层堆叠，没有任何连接操作。</p></li>
</ul>
</li>
<li><p><strong>RepPlainNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个3x3卷积层和一个RepConv层。</p></li>
<li><p>特点：通过RepConv层进行特征提取，增强了特征表示能力。</p></li>
</ul>
</li>
<li><p><strong>ResNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含两个3x3卷积层，并有一个残差连接（residual connection）。</p></li>
<li><p>特点：通过残差连接，解决了深层网络中的梯度消失问题，提高了训练效果。</p></li>
</ul>
</li>
<li><p><strong>RepResNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个3x3卷积层和一个RepConv层，并有一个残差连接。</p></li>
<li><p>特点：通过残差连接和RepConv层，进一步增强了特征提取能力。</p></li>
</ul>
</li>
<li><p><strong>P1-RepResNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个RepConv层和一个普通卷积层，并有一个残差连接。</p></li>
<li><p>特点：通过残差连接和RepConv层，增强了特征提取能力。</p></li>
</ul>
</li>
<li><p><strong>P2-RepResNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个RepConv层和一个普通卷积层，并有一个残差连接。</p></li>
<li><p>特点：与P1-RepResNet类似，但在某些情况下不推荐使用。</p></li>
</ul>
</li>
<li><p><strong>P3-RepResNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个RepConvN层（不含身份连接）和一个普通卷积层，并有一个残差连接。</p></li>
<li><p>特点：通过残差连接和RepConvN层，增强了特征提取能力。</p></li>
</ul>
</li>
<li><p><strong>P4-RepResNet</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个RepConvN层（不含身份连接）和一个普通卷积层，并有一个残差连接。</p></li>
<li><p>特点：与P3-RepResNet类似，但在某些情况下不推荐使用。</p></li>
</ul>
</li>
</ol>
<p>输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像通过输入层进入模型。</p></li>
<li><p>输入层通常是一个卷积层，用于初步提取图像的低级特征。</p></li>
</ul>
</li>
<li><p><strong>特征提取</strong>：</p>
<ul class="simple">
<li><p><strong>PlainNet</strong>：输入图像通过两个3x3卷积层进行特征提取。</p></li>
<li><p><strong>RepPlainNet</strong>：输入图像通过一个3x3卷积层和一个RepConv层进行特征提取。</p></li>
<li><p><strong>ResNet</strong>：输入图像通过两个3x3卷积层进行特征提取，并通过残差连接将输入直接传递到输出。</p></li>
<li><p><strong>RepResNet</strong>：输入图像通过一个3x3卷积层和一个RepConv层进行特征提取，并通过残差连接将输入直接传递到输出。</p></li>
<li><p><strong>P1-RepResNet</strong>：输入图像通过一个RepConv层和一个普通卷积层进行特征提取，并通过残差连接将输入直接传递到输出。</p></li>
<li><p><strong>P2-RepResNet</strong>：与P1-RepResNet类似，但在某些情况下不推荐使用。</p></li>
<li><p><strong>P3-RepResNet</strong>：输入图像通过一个RepConvN层（不含身份连接）和一个普通卷积层进行特征提取，并通过残差连接将输入直接传递到输出。</p></li>
<li><p><strong>P4-RepResNet</strong>：与P3-RepResNet类似，但在某些情况下不推荐使用。</p></li>
</ul>
</li>
<li><p><strong>特征聚合</strong>：</p>
<ul class="simple">
<li><p><strong>PlainNet</strong>：通过卷积层的堆叠进行特征聚合。</p></li>
<li><p><strong>RepPlainNet</strong>：通过卷积层和RepConv层的组合进行特征聚合。</p></li>
<li><p><strong>ResNet</strong>：通过卷积层和残差连接进行特征聚合。</p></li>
<li><p><strong>RepResNet</strong>：通过卷积层、RepConv层和残差连接进行特征聚合。</p></li>
<li><p><strong>P1-RepResNet</strong>：通过RepConv层、普通卷积层和残差连接进行特征聚合。</p></li>
<li><p><strong>P2-RepResNet</strong>：与P1-RepResNet类似，但在某些情况下不推荐使用。</p></li>
<li><p><strong>P3-RepResNet</strong>：通过RepConvN层、普通卷积层和残差连接进行特征聚合。</p></li>
<li><p><strong>P4-RepResNet</strong>：与P3-RepResNet类似，但在某些情况下不推荐使用。</p></li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终的特征通过输出层进行处理，生成目标检测结果。</p></li>
<li><p>输出层通常是一个全连接层或卷积层，用于生成目标检测的类别和位置。</p></li>
</ul>
</li>
</ol>
<hr class="docutils" />
<p>图表展示了几种不同的模型结构：普通模型、带辅助头的模型、独立分配器、引导头分配器以及粗到细引导头分配器。每种模型结构都采用了不同的标签分配方法，以提高模型的性能。以下是对图表内容的详细分析和总结。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>普通模型（Normal model）</strong>：</p>
<ul class="simple">
<li><p>结构：包含多个卷积层和检测层。</p></li>
<li><p>特点：传统的目标检测模型，通过卷积层提取特征，并通过检测层进行目标检测。</p></li>
</ul>
</li>
<li><p><strong>带辅助头的模型（Model with auxiliary head）</strong>：</p>
<ul class="simple">
<li><p>结构：在普通模型的基础上，增加了一个辅助头（Aux Head）。</p></li>
<li><p>特点：辅助头用于辅助主检测头（Lead Head）进行特征提取和目标检测，提高模型的检测性能。</p></li>
</ul>
</li>
<li><p><strong>独立分配器（Independent assigner）</strong>：</p>
<ul class="simple">
<li><p>结构：包含主检测头和辅助头，每个头都有独立的标签分配器（Assigner）。</p></li>
<li><p>特点：每个检测头独立进行标签分配和损失计算，互不干扰。</p></li>
</ul>
</li>
<li><p><strong>引导头分配器（Lead guided assigner）</strong>：</p>
<ul class="simple">
<li><p>结构：包含主检测头和辅助头，标签分配由主检测头引导。</p></li>
<li><p>特点：主检测头引导标签分配，辅助头根据主检测头的预测结果进行标签分配和损失计算。</p></li>
</ul>
</li>
<li><p><strong>粗到细引导头分配器（Coarse-to-fine lead guided assigner）</strong>：</p>
<ul class="simple">
<li><p>结构：包含主检测头和辅助头，标签分配由粗到细进行。</p></li>
<li><p>特点：标签分配过程分为粗略分配和精细分配两个阶段，主检测头进行粗略分配，辅助头进行精细分配，提高标签分配的准确性。</p></li>
</ul>
</li>
</ol>
<p>输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像通过输入层进入模型。</p></li>
<li><p>输入层通常是一个卷积层，用于初步提取图像的低级特征。</p></li>
</ul>
</li>
<li><p><strong>特征提取</strong>：</p>
<ul class="simple">
<li><p><strong>普通模型</strong>：输入图像通过多个卷积层进行特征提取，最后通过检测层进行目标检测。</p></li>
<li><p><strong>带辅助头的模型</strong>：输入图像通过多个卷积层进行特征提取，特征同时传递给主检测头和辅助头，辅助头辅助主检测头进行目标检测。</p></li>
<li><p><strong>独立分配器</strong>：输入图像通过多个卷积层进行特征提取，特征同时传递给主检测头和辅助头，每个头独立进行标签分配和损失计算。</p></li>
<li><p><strong>引导头分配器</strong>：输入图像通过多个卷积层进行特征提取，特征同时传递给主检测头和辅助头，主检测头引导标签分配，辅助头根据主检测头的预测结果进行标签分配和损失计算。</p></li>
<li><p><strong>粗到细引导头分配器</strong>：输入图像通过多个卷积层进行特征提取，特征同时传递给主检测头和辅助头，标签分配过程分为粗略分配和精细分配两个阶段，主检测头进行粗略分配，辅助头进行精细分配。</p></li>
</ul>
</li>
<li><p><strong>标签分配</strong>：</p>
<ul class="simple">
<li><p><strong>普通模型</strong>：通过检测层直接进行目标检测。</p></li>
<li><p><strong>带辅助头的模型</strong>：辅助头辅助主检测头进行标签分配和目标检测。</p></li>
<li><p><strong>独立分配器</strong>：主检测头和辅助头独立进行标签分配和损失计算。</p></li>
<li><p><strong>引导头分配器</strong>：主检测头引导标签分配，辅助头根据主检测头的预测结果进行标签分配和损失计算。</p></li>
<li><p><strong>粗到细引导头分配器</strong>：标签分配过程分为粗略分配和精细分配两个阶段，主检测头进行粗略分配，辅助头进行精细分配。</p></li>
</ul>
</li>
<li><p><strong>损失计算</strong>：</p>
<ul class="simple">
<li><p><strong>普通模型</strong>：通过检测层直接进行损失计算。</p></li>
<li><p><strong>带辅助头的模型</strong>：辅助头辅助主检测头进行损失计算。</p></li>
<li><p><strong>独立分配器</strong>：主检测头和辅助头独立进行损失计算。</p></li>
<li><p><strong>引导头分配器</strong>：主检测头引导标签分配，辅助头根据主检测头的预测结果进行损失计算。</p></li>
<li><p><strong>粗到细引导头分配器</strong>：标签分配过程分为粗略分配和精细分配两个阶段，主检测头进行粗略分配，辅助头进行精细分配，并进行损失计算。</p></li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终的特征通过输出层进行处理，生成目标检测结果。</p></li>
<li><p>输出层通常是一个全连接层或卷积层，用于生成目标检测的类别和位置。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>普通模型</strong>：传统的目标检测模型，通过卷积层提取特征，并通过检测层进行目标检测。</p></li>
<li><p><strong>带辅助头的模型</strong>：通过增加辅助头，辅助主检测头进行特征提取和目标检测，提高模型的检测性能。</p></li>
<li><p><strong>独立分配器</strong>：主检测头和辅助头独立进行标签分配和损失计算，互不干扰。</p></li>
<li><p><strong>引导头分配器</strong>：主检测头引导标签分配，辅助头根据主检测头的预测结果进行标签分配和损失计算。</p></li>
<li><p><strong>粗到细引导头分配器</strong>：标签分配过程分为粗略分配和精细分配两个阶段，主检测头进行粗略分配，辅助头进行精细分配，提高标签分配的准确性。</p></li>
</ul>
<p>通过对几种模型结构的分析，可以看出每种模型在特征提取、标签分配和损失计算方面都有其独特的策略和优势。带辅助头的模型和引导头分配器通过引入辅助头和引导标签分配，提高了模型的检测性能和标签分配的准确性。</p>
<hr class="docutils" />
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>模型结构</strong>：</p>
<ul class="simple">
<li><p><strong>左侧图</strong>：展示了一个包含三层3x3卷积层的堆叠结构，每层卷积层的输出通道数为c。</p></li>
<li><p><strong>右侧图</strong>：展示了五种不同的RepConv替换位置（a, b, c, d, e），蓝色圆圈表示用RepConv替换常规卷积层的位置。</p></li>
</ul>
</li>
<li><p><strong>RepConv</strong>：</p>
<ul class="simple">
<li><p>RepConv是一种改进的卷积操作，通常用于提高模型的特征提取能力和计算效率。</p></li>
<li><p>在图中，蓝色圆圈标记了用RepConv替换常规卷积层的位置。</p></li>
</ul>
</li>
</ol>
<p>输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像通过输入层进入模型。</p></li>
<li><p>输入层通常是一个卷积层，用于初步提取图像的低级特征。</p></li>
</ul>
</li>
<li><p><strong>特征提取</strong>：</p>
<ul class="simple">
<li><p>输入图像通过三层堆叠的3x3卷积层进行特征提取。</p></li>
<li><p>每层卷积层的输出通道数为c。</p></li>
<li><p>在特定位置（由右侧图中的蓝色圆圈标记）用RepConv替换常规卷积层，以提高特征提取的效果。</p></li>
</ul>
</li>
<li><p><strong>RepConv替换位置</strong>：</p>
<ul class="simple">
<li><p><strong>位置a</strong>：在第一层卷积层的位置用RepConv替换。</p></li>
<li><p><strong>位置b</strong>：在第二层卷积层的位置用RepConv替换。</p></li>
<li><p><strong>位置c</strong>：在第三层卷积层的位置用RepConv替换。</p></li>
<li><p><strong>位置d</strong>：在第一层和第二层卷积层的位置用RepConv替换。</p></li>
<li><p><strong>位置e</strong>：在第一层、第二层和第三层卷积层的位置用RepConv替换。</p></li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终的特征通过输出层进行处理，生成目标检测或分类结果。</p></li>
<li><p>输出层通常是一个全连接层或卷积层，用于生成最终的预测结果。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>模型结构</strong>：该模型使用了三层堆叠的3x3卷积层，并在特定位置用RepConv替换常规卷积层，以提高特征提取的效果。</p></li>
<li><p><strong>RepConv替换位置</strong>：右侧图展示了五种不同的RepConv替换位置（a, b, c, d, e），每种替换位置可能对模型的性能产生不同的影响。</p></li>
<li><p><strong>输入输出流程</strong>：输入图像通过三层堆叠的3x3卷积层进行特征提取，在特定位置用RepConv替换常规卷积层，最终通过输出层生成预测结果。</p></li>
</ul>
<p>结论</p>
<p>通过对模型结构和输入输出流程的分析，可以看出该模型通过在特定位置用RepConv替换常规卷积层，提高了特征提取的效果。根据具体应用场景的需求，可以选择合适的RepConv替换位置，以优化模型的性能。</p>
<hr class="docutils" />
<p>图表展示了四种不同的卷积块结构：Dark block、CSPDark block、RDark block 和 RCSPDark block。这些块结构通过调整1x1卷积层和3x3卷积层的位置来适应重新参数化的模型设计策略。以下是对图表内容的详细分析和总结。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>Dark block</strong>：</p>
<ul class="simple">
<li><p>结构：包含一个1x1卷积层和一个3x3卷积层。</p></li>
<li><p>输入通道数为c，1x1卷积层的输出通道数为c/2，3x3卷积层的输出通道数为c。</p></li>
</ul>
</li>
<li><p><strong>CSPDark block</strong>：</p>
<ul class="simple">
<li><p>结构：包含两个并行的路径，每个路径包含一个1x1卷积层和一个3x3卷积层。</p></li>
<li><p>输入通道数为c，1x1卷积层的输出通道数为c/2，3x3卷积层的输出通道数为c/2。</p></li>
</ul>
</li>
<li><p><strong>RDark block</strong>：</p>
<ul class="simple">
<li><p>结构：与Dark block相反，包含一个3x3卷积层和一个1x1卷积层。</p></li>
<li><p>输入通道数为c，3x3卷积层的输出通道数为c/2，1x1卷积层的输出通道数为c。</p></li>
</ul>
</li>
<li><p><strong>RCSPDark block</strong>：</p>
<ul class="simple">
<li><p>结构：与CSPDark block相反，包含两个并行的路径，每个路径包含一个3x3卷积层和一个1x1卷积层。</p></li>
<li><p>输入通道数为c，3x3卷积层的输出通道数为c/2，1x1卷积层的输出通道数为c/2。</p></li>
</ul>
</li>
</ol>
<p>输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像通过输入层进入模型。</p></li>
<li><p>输入层通常是一个卷积层，用于初步提取图像的低级特征。</p></li>
</ul>
</li>
<li><p><strong>特征提取</strong>：</p>
<ul class="simple">
<li><p><strong>Dark block</strong>：</p>
<ul>
<li><p>输入特征图通过1x1卷积层，输出通道数为c/2。</p></li>
<li><p>然后通过3x3卷积层，输出通道数为c。</p></li>
</ul>
</li>
<li><p><strong>CSPDark block</strong>：</p>
<ul>
<li><p>输入特征图分为两条并行路径，每条路径通过1x1卷积层，输出通道数为c/2。</p></li>
<li><p>然后每条路径通过3x3卷积层，输出通道数为c/2。</p></li>
<li><p>最后将两条路径的输出特征图进行拼接。</p></li>
</ul>
</li>
<li><p><strong>RDark block</strong>：</p>
<ul>
<li><p>输入特征图通过3x3卷积层，输出通道数为c/2。</p></li>
<li><p>然后通过1x1卷积层，输出通道数为c。</p></li>
</ul>
</li>
<li><p><strong>RCSPDark block</strong>：</p>
<ul>
<li><p>输入特征图分为两条并行路径，每条路径通过3x3卷积层，输出通道数为c/2。</p></li>
<li><p>然后每条路径通过1x1卷积层，输出通道数为c/2。</p></li>
<li><p>最后将两条路径的输出特征图进行拼接。</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终的特征通过输出层进行处理，生成目标检测或分类结果。</p></li>
<li><p>输出层通常是一个全连接层或卷积层，用于生成最终的预测结果。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>Dark block</strong>：包含一个1x1卷积层和一个3x3卷积层，用于特征提取。</p></li>
<li><p><strong>CSPDark block</strong>：包含两个并行的路径，每个路径包含一个1x1卷积层和一个3x3卷积层，用于特征提取和拼接。</p></li>
<li><p><strong>RDark block</strong>：与Dark block相反，包含一个3x3卷积层和一个1x1卷积层，用于特征提取。</p></li>
<li><p><strong>RCSPDark block</strong>：与CSPDark block相反，包含两个并行的路径，每个路径包含一个3x3卷积层和一个1x1卷积层，用于特征提取和拼接。</p></li>
</ul>
<p>结论</p>
<p>通过对模型结构和输入输出流程的分析，可以看出这些卷积块结构通过调整1x1卷积层和3x3卷积层的位置，适应了重新参数化的模型设计策略。根据具体应用场景的需求，可以选择合适的卷积块结构，以优化模型的性能。</p>
<hr class="docutils" />
<p>图表展示了不同方法在辅助头和主头上的目标性图（Objectness Map）预测结果。以下是对图表内容的详细分析和总结。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>输入图像</strong>：</p>
<ul class="simple">
<li><p>图(a)展示了一个包含多个人物的输入图像。</p></li>
</ul>
</li>
<li><p><strong>目标性图预测</strong>：</p>
<ul class="simple">
<li><p>图(b)和图(c)展示了独立辅助头和独立主头的目标性图预测结果。</p></li>
<li><p>图(d)和图(e)展示了引导辅助头和引导主头的目标性图预测结果。</p></li>
</ul>
</li>
<li><p><strong>红色圆圈</strong>：</p>
<ul class="simple">
<li><p>红色圆圈标记了目标性图中高目标性区域的位置，这些区域通常对应于输入图像中的目标物体（如人物）。</p></li>
</ul>
</li>
</ol>
<p>详细分析</p>
<ol class="arabic simple">
<li><p><strong>独立辅助头和独立主头</strong>：</p>
<ul class="simple">
<li><p>图(b)和图(c)分别展示了独立辅助头和独立主头的目标性图预测结果。</p></li>
<li><p>从图中可以看出，独立辅助头和独立主头在某些区域的目标性预测较为分散，可能存在漏检或误检的情况。</p></li>
</ul>
</li>
<li><p><strong>引导辅助头和引导主头</strong>：</p>
<ul class="simple">
<li><p>图(d)和图(e)分别展示了引导辅助头和引导主头的目标性图预测结果。</p></li>
<li><p>从图中可以看出，引导辅助头和引导主头在目标性预测上更加集中，红色圆圈标记的高目标性区域更为明显，预测结果更加准确。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>输入图像</strong>：图(a)展示了一个包含多个人物的输入图像。</p></li>
<li><p><strong>独立辅助头和独立主头</strong>：图(b)和图(c)展示了独立辅助头和独立主头的目标性图预测结果，预测结果较为分散，可能存在漏检或误检的情况。</p></li>
<li><p><strong>引导辅助头和引导主头</strong>：图(d)和图(e)展示了引导辅助头和引导主头的目标性图预测结果，预测结果更加集中，红色圆圈标记的高目标性区域更为明显，预测结果更加准确。</p></li>
</ul>
<p>结论</p>
<p>通过对不同方法在辅助头和主头上的目标性图预测结果的分析，可以看出引导辅助头和引导主头在目标性预测上表现更为优越，预测结果更加集中和准确。这表明引导方法在目标检测任务中具有更好的性能，能够更准确地识别输入图像中的目标物体。</p>
<hr class="docutils" />
<p>这个图表展示了在MS COCO min-val数据集上不同目标检测模型的性能比较。横轴表示V100 GPU上单个批次的推理时间（毫秒），纵轴表示平均精度（AP）百分比。图表中的每个点代表一个模型的性能，点的位置由其推理时间和平均精度决定。</p>
<p>以下是对图表中模型性能的分析：</p>
<ol class="arabic simple">
<li><p><strong>YOLOv7</strong> 系列模型：</p>
<ul class="simple">
<li><p>YOLOv7在推理时间和平均精度上表现出色，尤其是YOLOv7-E6E，达到了56.80%的AP，推理时间约为30ms。</p></li>
<li><p>YOLOv7的多个变体（如YOLOv7-E6、YOLOv7-D6等）在推理时间和精度上均表现优异，显示了其在不同配置下的强大性能。</p></li>
</ul>
</li>
<li><p><strong>YOLOv6</strong> 系列模型：</p>
<ul class="simple">
<li><p>YOLOv6系列模型的性能也相当不错，尤其是YOLOv6-L，达到了52.30%的AP，推理时间约为20ms。</p></li>
<li><p>这些模型在推理时间和精度上与YOLOv7系列相近，但略逊色于YOLOv7。</p></li>
</ul>
</li>
<li><p><strong>YOLOv5</strong> 系列模型：</p>
<ul class="simple">
<li><p>YOLOv5系列模型的性能稍逊于YOLOv6和YOLOv7，但仍然表现良好。例如，YOLOv5-X的AP为50.70%，推理时间约为15ms。</p></li>
</ul>
</li>
<li><p><strong>其他模型</strong>：</p>
<ul class="simple">
<li><p>图表中还包括了一些其他模型，如EfficientDet-D7、DETR-R101-DC5等。这些模型的推理时间较长，精度也不如YOLO系列。</p></li>
<li><p>例如，EfficientDet-D7的AP为52.20%，但推理时间超过100ms，显示了其在速度上的劣势。</p></li>
</ul>
</li>
<li><p><strong>性能总结</strong>：</p>
<ul class="simple">
<li><p>总体来看，YOLOv7系列模型在推理时间和平均精度上均表现出色，尤其是YOLOv7-E6E，显示了其在目标检测任务中的强大性能。</p></li>
<li><p>YOLOv6和YOLOv5系列模型也表现良好，但在某些配置下略逊于YOLOv7。</p></li>
<li><p>其他模型虽然在某些方面表现不错，但在推理时间和精度的平衡上不如YOLO系列。</p></li>
</ul>
</li>
</ol>
<p>图表中的注释还指出，YOLOv7比其他模型快了1200%，进一步强调了其在速度上的优势。</p>
<hr class="docutils" />
<p>这个图表展示了在MS COCO数据集上不同目标检测模型的性能比较，分别在单个批次（batch=1）和批次为32（batch=32）的情况下进行评估。横轴表示V100 GPU上的推理时间（毫秒），纵轴表示平均精度（AP）百分比。图表中的每个点代表一个模型的性能，点的位置由其推理时间和平均精度决定。</p>
<p>左图：V100 batch=1 推理时间</p>
<ol class="arabic simple">
<li><p><strong>YOLOv7 系列模型</strong>：</p>
<ul class="simple">
<li><p>YOLOv7在推理时间和平均精度上表现出色，尤其是YOLOv7-E6E，达到了56.8%的AP，推理时间约为30ms。</p></li>
<li><p>YOLOv7的多个变体（如YOLOv7-E6、YOLOv7-D6等）在推理时间和精度上均表现优异，显示了其在不同配置下的强大性能。</p></li>
</ul>
</li>
<li><p><strong>YOLOv6 系列模型</strong>：</p>
<ul class="simple">
<li><p>YOLOv6系列模型的性能也相当不错，尤其是YOLOv6-L，达到了52.3%的AP，推理时间约为20ms。</p></li>
<li><p>这些模型在推理时间和精度上与YOLOv7系列相近，但略逊色于YOLOv7。</p></li>
</ul>
</li>
<li><p><strong>YOLOv5 系列模型</strong>：</p>
<ul class="simple">
<li><p>YOLOv5系列模型的性能稍逊于YOLOv6和YOLOv7，但仍然表现良好。例如，YOLOv5-X的AP为50.7%，推理时间约为15ms。</p></li>
</ul>
</li>
<li><p><strong>Scaled-YOLOv4</strong>：</p>
<ul class="simple">
<li><p>Scaled-YOLOv4的性能也不错，但在推理时间和精度上略逊于YOLOv7和YOLOv6。</p></li>
</ul>
</li>
</ol>
<p>右图：V100 batch=32 平均推理时间</p>
<ol class="arabic simple">
<li><p><strong>YOLOv7 系列模型</strong>：</p>
<ul class="simple">
<li><p>YOLOv7在批次为32的情况下依然表现出色，尤其是YOLOv7-E6E，达到了56.8%的AP，推理时间约为3ms。</p></li>
<li><p>YOLOv7的多个变体在推理时间和精度上均表现优异，显示了其在不同配置下的强大性能。</p></li>
</ul>
</li>
<li><p><strong>YOLOv6 系列模型</strong>：</p>
<ul class="simple">
<li><p>YOLOv6系列模型在批次为32的情况下也表现良好，尤其是YOLOv6-L，达到了52.3%的AP，推理时间约为2ms。</p></li>
</ul>
</li>
<li><p><strong>YOLOv5 系列模型</strong>：</p>
<ul class="simple">
<li><p>YOLOv5系列模型在批次为32的情况下表现稍逊于YOLOv6和YOLOv7，但仍然表现良好。例如，YOLOv5-X的AP为50.7%，推理时间约为1.5ms。</p></li>
</ul>
</li>
<li><p><strong>Scaled-YOLOv4</strong>：</p>
<ul class="simple">
<li><p>Scaled-YOLOv4在批次为32的情况下表现也不错，但在推理时间和精度上略逊于YOLOv7和YOLOv6。</p></li>
</ul>
</li>
</ol>
<p>性能总结</p>
<ul class="simple">
<li><p><strong>YOLOv7</strong> 系列模型在单个批次和批次为32的情况下均表现出色，显示了其在推理时间和平均精度上的强大性能。</p></li>
<li><p><strong>YOLOv6</strong> 系列模型在推理时间和精度上也表现良好，但略逊色于YOLOv7。</p></li>
<li><p><strong>YOLOv5</strong> 系列模型在推理时间和精度上稍逊于YOLOv6和YOLOv7，但仍然表现良好。</p></li>
<li><p><strong>Scaled-YOLOv4</strong> 在推理时间和精度上表现也不错，但略逊于YOLOv7和YOLOv6。</p></li>
</ul>
<p>图表中的注释还指出，YOLOv7在单个批次情况下比其他模型快了1200%，在批次为32的情况下快了1500%，进一步强调了其在速度上的优势。</p>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="YOLOS.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">YOLOS</p>
      </div>
    </a>
    <a class="right-next"
       href="Dy-yolov7.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">DY-yolov7</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By isLinXu
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022, isLinXu.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>