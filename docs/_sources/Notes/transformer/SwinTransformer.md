# Swin Transformer

**标题：** Swin Transformer: Hierarchical Vision Transformer using Shifted Windows

**作者：** Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo，来自 Microsoft Research Asia。

**摘要：**
- 提出了一种新的 Transformer 架构，称为 Swin Transformer，作为计算机视觉的通用骨干网络。
- 针对视觉领域特有的挑战，如视觉实体尺度变化大和图像像素分辨率高，提出了一种分层 Transformer，通过移动窗口计算表示，提高了效率。
- Swin Transformer 在多个视觉任务上表现出色，包括图像分类、目标检测和语义分割，并在 COCO 和 ADE20K 数据集上取得了新的最佳性能。

**1. 工作内容与动机：**
- 动机：现有的 Transformer 模型在计算机视觉领域的表现不如在 NLP 领域，需要解决视觉领域特有的挑战。
- 工作：提出了 Swin Transformer，一种适用于计算机视觉任务的分层 Transformer 架构。

**2. 试图解决的问题：**
- 解决的问题是 Transformer 在计算机视觉领域应用时的效率和性能问题。

**3. 是否是一个新的问题？**
- 是一个新的问题，因为 Swin Transformer 提供了一种新的视角和解决方案来克服视觉任务中 Transformer 的局限性。

**4. 科学假设：**
- 假设通过引入移动窗口和分层结构，Transformer 能够更有效地处理视觉数据，并且在多种视觉任务中取得更好的性能。

**5. 相关研究：**
- 相关研究包括 CNN 和 Transformer 在图像分类、目标检测和语义分割等任务上的应用。
- 归类：主要归类于计算机视觉和深度学习模型架构创新。
- 值得关注的研究员：论文作者团队，以及在 CV 和 NLP 领域内对 Transformer 有贡献的研究者。

**6. 解决方案的关键：**
- 关键是提出了一种新的移动窗口机制，通过在连续层之间移动窗口划分，实现了跨窗口的连接，同时保持了计算的线性复杂度。

**7. 实验设计：**
- 实验设计包括在 ImageNet-1K、COCO 和 ADE20K 数据集上进行图像分类、目标检测和语义分割任务的评估。

**8. 定量评估的数据集与代码开源情况：**
- 使用了 ImageNet-1K、COCO 和 ADE20K 数据集进行评估。
- 代码已在 GitHub 上开源：https://github.com/microsoft/Swin-Transformer。

**9. 实验结果与科学假设的支持：**
- 实验结果表明 Swin Transformer 在多个视觉任务上取得了优异的性能，支持了提出的科学假设。

**10. 论文贡献：**
- 提出了一种新的 Transformer 架构，适用于计算机视觉任务，并且在多个基准测试中取得了新的最佳性能。

**11. 下一步工作：**
- 未来的工作可以探索 Swin Transformer 在其他视觉任务上的应用，如视频理解、3D 视觉等，以及进一步优化模型结构和训练策略。

### 回答问题

1. **这篇论文做了什么工作，它的动机是什么？**
   - 论文提出了一种新的 Transformer 架构，Swin Transformer，用于计算机视觉任务。动机是解决现有 Transformer 模型在视觉任务中的效率和性能问题。

2. **这篇论文试图解决什么问题？**
   - 试图解决 Transformer 在计算机视觉领域应用时面临的挑战，如尺度变化和高分辨率像素的处理。

3. **这是否是一个新的问题？**
   - 是一个新的问题，提出了一种新的解决方案来克服现有模型的局限性。

4. **这篇文章要验证一个什么科学假设？**
   - 验证通过引入移动窗口和分层结构，Transformer 能够更有效地处理视觉数据，并在多种视觉任务中取得更好的性能。

5. **有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？**
   - 相关研究包括 CNN 和 Transformer 在图像分类、目标检测和语义分割等任务的应用。归类于计算机视觉和深度学习模型架构创新。值得关注的研究员包括论文作者团队和在 CV 和 NLP 领域内对 Transformer 有贡献的研究者。

6. **论文中提到的解决方案之关键是什么？**
   - 解决方案的关键是引入了移动窗口机制和分层结构，提高了模型的效率和性能。

7. **论文中的实验是如何设计的？**
   - 实验设计包括在 ImageNet-1K、COCO 和 ADE20K 数据集上进行图像分类、目标检测和语义分割任务的评估。

8. **用于定量评估的数据集上什么？代码有没有开源？**
   - 使用了 ImageNet-1K、COCO 和 ADE20K 数据集。代码已在 GitHub 上开源。

9. **论文中的实验及结果有没有很好地支持需要验证的科学假设？**
   - 实验结果表明 Swin Transformer 在多个视觉任务上取得了优异的性能，很好地支持了科学假设。

10. **这篇论文到底有什么贡献？**
    - 提出了一种新的 Transformer 架构，适用于计算机视觉任务，并在多个基准测试中取得了新的最佳性能。

11. **下一步呢？有什么工作可以继续深入？**
    - 未来的工作可以探索 Swin Transformer 在其他视觉任务上的应用，并进一步优化模型结构和训练策略。


---
<img width="551" alt="swin-fig1" src="https://github.com/isLinXu/issues/assets/59380685/6f797f27-2c90-4c6d-9c5b-232ed7b0d7c1">


这个图表展示了Swin Transformer和ViT（Vision Transformer）在图像分类、分割和检测任务中的特征图构建方式的对比。以下是对图表结构的详细分析和总结：

图表结构分析

1. **子图**：
   - 图表包含两个子图，每个子图表示一种模型的特征图构建方式：
     - **左侧子图 (a)**：Swin Transformer的特征图构建方式。
     - **右侧子图 (b)**：ViT的特征图构建方式。

2. **特征图层次**：
   - 每个子图中展示了不同层次的特征图：
     - **Swin Transformer**：特征图从低分辨率到高分辨率逐层构建，特征图的分辨率逐层减小（16x、8x、4x）。
     - **ViT**：特征图保持单一分辨率（16x），没有层次结构。

3. **特征图表示**：
   - **灰色区域**：表示图像块（image patches）。
   - **红色网格**：表示局部窗口（local windows）或特征图的分割方式。

总结

1. **Swin Transformer**：
   - **层次化特征图**：通过在更深的层次中合并图像块（灰色区域）来构建层次化的特征图。
   - **局部自注意力**：在每个局部窗口（红色网格）内计算自注意力，从而使计算复杂度相对于输入图像大小呈线性增长。
   - **通用骨干网络**：由于其层次化特征图和局部自注意力计算方式，Swin Transformer可以作为图像分类和密集识别任务的通用骨干网络。

2. **ViT**：
   - **单一分辨率特征图**：生成单一低分辨率的特征图（16x），没有层次结构。
   - **全局自注意力**：在整个图像上计算自注意力，从而使计算复杂度相对于输入图像大小呈二次方增长。
   - **计算复杂度高**：由于全局自注意力的计算方式，ViT在处理高分辨率图像时计算复杂度较高。

结论

从图表中可以看出，Swin Transformer和ViT在特征图构建方式和计算复杂度上的主要区别：

1. **特征图构建方式**：
   - **Swin Transformer**：采用层次化特征图构建方式，通过合并图像块逐层构建特征图，适用于多种视觉任务。
   - **ViT**：生成单一分辨率的特征图，没有层次结构，主要用于图像分类任务。

2. **计算复杂度**：
   - **Swin Transformer**：在局部窗口内计算自注意力，计算复杂度相对于输入图像大小呈线性增长，适合处理高分辨率图像。
   - **ViT**：在整个图像上计算自注意力，计算复杂度相对于输入图像大小呈二次方增长，处理高分辨率图像时计算复杂度较高。

3. **应用场景**：
   - **Swin Transformer**：由于其层次化特征图和局部自注意力计算方式，可以作为图像分类、分割和检测等任务的通用骨干网络。
   - **ViT**：由于其全局自注意力计算方式，主要适用于图像分类任务，在处理高分辨率图像时计算复杂度较高。

总体来看，Swin Transformer在特征图构建方式和计算复杂度上具有显著优势，适用于更广泛的视觉任务。


---

<img width="503" alt="swin-fig2" src="https://github.com/isLinXu/issues/assets/59380685/e761fa1e-38a4-45c4-8c06-615fe937a6ae">


这个图表展示了Swin Transformer架构中“shifted window”方法的示意图，说明了在不同层次中如何通过窗口偏移来计算自注意力。以下是对图表结构的详细分析和总结：

图表结构分析

1. **子图**：
   - 图表包含两个子图，每个子图表示一个层次的窗口划分和自注意力计算方式：
     - **左侧子图 (Layer l)**：表示第l层的窗口划分方式。
     - **右侧子图 (Layer l+1)**：表示第l+1层的窗口划分方式。

2. **窗口划分**：
   - **Layer l**：
     - 图像被划分为多个不重叠的局部窗口（红色边框）。
     - 每个局部窗口内计算自注意力。
   - **Layer l+1**：
     - 窗口划分方式发生偏移（shifted），形成新的局部窗口。
     - 新的局部窗口跨越了第l层窗口的边界，从而在不同窗口之间建立连接。

3. **图例**：
   - **红色边框**：表示局部窗口，用于计算自注意力。
   - **灰色区域**：表示图像块（patch）。

总结

1. **Layer l（第l层）**：
   - 图像被划分为多个不重叠的局部窗口。
   - 自注意力计算仅在每个局部窗口内进行，窗口之间没有直接连接。

2. **Layer l+1（第l+1层）**：
   - 窗口划分方式发生偏移，形成新的局部窗口。
   - 新的局部窗口跨越了第l层窗口的边界，从而在不同窗口之间建立连接。
   - 自注意力计算在新的局部窗口内进行，提供了跨窗口的连接。

结论

从图表中可以看出，Swin Transformer通过“shifted window”方法在不同层次中实现了局部窗口内和跨窗口的自注意力计算：

1. **局部自注意力**：
   - 在每个层次中，图像被划分为多个局部窗口，自注意力计算仅在每个局部窗口内进行。
   - 这种方式使得计算复杂度相对于输入图像大小呈线性增长，适合处理高分辨率图像。

2. **窗口偏移**：
   - 在相邻层次之间，窗口划分方式发生偏移，形成新的局部窗口。
   - 新的局部窗口跨越了前一层窗口的边界，从而在不同窗口之间建立连接。
   - 这种方式提供了跨窗口的连接，使得特征图在不同层次之间能够更好地融合信息。

3. **计算效率**：
   - 通过局部自注意力和窗口偏移的方法，Swin Transformer在保持计算效率的同时，能够在不同层次之间有效地融合信息。
   - 这种方法不仅适用于图像分类任务，还适用于图像分割和检测等密集识别任务。

总体来看，Swin Transformer通过“shifted window”方法在不同层次中实现了高效的自注意力计算和信息融合，具有显著的计算效率和适用性。


---

<img width="1052" alt="swin-fig3" src="https://github.com/isLinXu/issues/assets/59380685/ed7fda74-572e-420d-811e-0b14e7bb2499">

这个图表展示了Swin Transformer（Swin-T）的架构以及两个连续的Swin Transformer块的详细结构。以下是对图表结构的详细分析和总结：

图表结构分析

1. **子图**：
   - 图表包含两个子图：
     - **左侧子图 (a)**：Swin Transformer的整体架构。
     - **右侧子图 (b)**：两个连续的Swin Transformer块的详细结构。

2. **左侧子图 (a) - Swin Transformer的整体架构**：
   - **输入图像**：尺寸为 \(H \times W \times 3\)。
   - **Stage 1**：
     - 图像被划分为非重叠的图像块（patch），每个图像块的尺寸为 \(4 \times 4\)。
     - 图像块通过线性嵌入层，输出尺寸为 \(\frac{H}{4} \times \frac{W}{4} \times 48\)。
     - 包含两个Swin Transformer块。
   - **Stage 2**：
     - 通过Patch Merging层，尺寸变为 \(\frac{H}{8} \times \frac{W}{8} \times 96\)。
     - 包含两个Swin Transformer块。
   - **Stage 3**：
     - 通过Patch Merging层，尺寸变为 \(\frac{H}{16} \times \frac{W}{16} \times 192\)。
     - 包含六个Swin Transformer块。
   - **Stage 4**：
     - 通过Patch Merging层，尺寸变为 \(\frac{H}{32} \times \frac{W}{32} \times 384\)。
     - 包含两个Swin Transformer块。

3. **右侧子图 (b) - 两个连续的Swin Transformer块**：
   - **第一个Swin Transformer块**：
     - **W-MSA**（Window-based Multi-Head Self Attention）：基于窗口的多头自注意力模块。
     - **MLP**（Multi-Layer Perceptron）：多层感知机。
     - **LN**（Layer Normalization）：层归一化。
   - **第二个Swin Transformer块**：
     - **SW-MSA**（Shifted Window-based Multi-Head Self Attention）：基于偏移窗口的多头自注意力模块。
     - **MLP**（Multi-Layer Perceptron）：多层感知机。
     - **LN**（Layer Normalization）：层归一化。

总结

1. **Swin Transformer整体架构**：
   - Swin Transformer通过将输入图像划分为非重叠的图像块，并逐层进行特征提取和尺寸缩减。
   - 整体架构分为四个阶段，每个阶段通过Patch Merging层进行尺寸缩减，并包含多个Swin Transformer块。

2. **Swin Transformer块的详细结构**：
   - 每个Swin Transformer块包含两个主要模块：基于窗口的多头自注意力模块（W-MSA或SW-MSA）和多层感知机（MLP）。
   - 第一个Swin Transformer块使用W-MSA，第二个Swin Transformer块使用SW-MSA，通过偏移窗口的方式在不同窗口之间建立连接。
   - 每个模块后面都跟有层归一化（LN）以稳定训练过程。

3. **计算效率和信息融合**：
   - Swin Transformer通过局部窗口内的自注意力计算（W-MSA）和跨窗口的自注意力计算（SW-MSA）实现高效的特征提取和信息融合。
   - 这种架构设计使得Swin Transformer在保持计算效率的同时，能够在不同层次之间有效地融合信息，适用于图像分类、分割和检测等任务。

结论

Swin Transformer通过分阶段的特征提取和尺寸缩减，以及基于窗口和偏移窗口的多头自注意力模块，实现了高效的计算和信息融合。其架构设计使其在处理高分辨率图像时具有显著的计算效率和适用性，适用于多种视觉任务。


---
<img width="506" alt="swin-fig4" src="https://github.com/isLinXu/issues/assets/59380685/2cfb11be-dae3-4087-8ffd-1f40dca568d9">


这个图表展示了在Swin Transformer中使用shifted window划分进行自注意力计算的高效批处理方法。以下是对图表结构的详细分析和总结：

图表结构分析

1. **子图**：
   - 图表包含四个主要步骤，每个步骤用一个子图表示：
     - **Window Partition**：窗口划分。
     - **Cyclic Shift**：循环移位。
     - **Masked MSA**：掩码多头自注意力计算。
     - **Reverse Cyclic Shift**：反向循环移位。

2. **步骤解析**：
   - **Window Partition（窗口划分）**：
     - 输入图像被划分为多个不重叠的局部窗口（红色边框）。
   - **Cyclic Shift（循环移位）**：
     - 对窗口进行循环移位，使得窗口的位置发生变化。
     - 图中用不同颜色（A、B、C）表示不同的窗口区域。
   - **Masked MSA（掩码多头自注意力计算）**：
     - 在循环移位后的窗口内进行掩码多头自注意力计算（masked MSA）。
     - 掩码用于确保自注意力计算仅在局部窗口内进行。
   - **Reverse Cyclic Shift（反向循环移位）**：
     - 对窗口进行反向循环移位，将窗口恢复到原始位置。
     - 通过这种方式，跨窗口的连接得以实现。

总结

1. **窗口划分**：
   - 输入图像首先被划分为多个不重叠的局部窗口，每个窗口内进行自注意力计算。

2. **循环移位**：
   - 对窗口进行循环移位，使得窗口的位置发生变化。
   - 这种移位方式确保了在不同窗口之间建立连接。

3. **掩码多头自注意力计算**：
   - 在循环移位后的窗口内进行掩码多头自注意力计算。
   - 掩码用于确保自注意力计算仅在局部窗口内进行，从而保持计算效率。

4. **反向循环移位**：
   - 对窗口进行反向循环移位，将窗口恢复到原始位置。
   - 通过这种方式，跨窗口的连接得以实现，确保了信息在不同窗口之间的有效融合。

结论

从图表中可以看出，Swin Transformer通过以下步骤实现了高效的自注意力计算和信息融合：

1. **窗口划分**：将输入图像划分为多个不重叠的局部窗口，每个窗口内进行自注意力计算。
2. **循环移位**：对窗口进行循环移位，使得窗口的位置发生变化，从而在不同窗口之间建立连接。
3. **掩码多头自注意力计算**：在循环移位后的窗口内进行掩码多头自注意力计算，确保计算仅在局部窗口内进行。
4. **反向循环移位**：对窗口进行反向循环移位，将窗口恢复到原始位置，确保信息在不同窗口之间的有效融合。

这种方法不仅保持了计算效率，还通过跨窗口的连接实现了信息的有效融合，使得Swin Transformer在处理高分辨率图像时具有显著的计算效率和适用性。