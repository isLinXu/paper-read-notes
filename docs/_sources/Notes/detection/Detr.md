# DETR

**标题：** End-to-End Object Detection with Transformers

**作者：** Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko

**机构：** Facebook AI

**摘要：** 本文提出了一种新的对象检测方法，将对象检测视为直接的集合预测问题。该方法简化了检测流程，去除了多个手工设计的组件，如非极大值抑制过程或锚点生成等，这些组件明确编码了我们对任务的先验知识。新框架称为DEtection TRansformer（DETR），其主要成分是一套基于全局损失的集合预测，通过二分图匹配强制进行唯一预测，以及一个基于transformer的编码器-解码器架构。DETR通过固定数量的已学习对象查询，直接并行输出最终的预测集合，简化了检测流程。DETR概念简单，不需要专门的库，与许多其他现代检测器不同。DETR在COCO对象检测数据集上展示了与高度优化的Faster RCNN基线相当的准确性和运行时间性能。此外，DETR可以轻松地推广到以统一的方式产生全景分割，并显著优于竞争基线。训练代码和预训练模型可在GitHub上获得。

**1. 工作内容与动机：**

- 工作内容：提出了一种端到端的对象检测方法DETR，使用transformers进行集合预测，简化了传统对象检测流程。
- 动机：传统对象检测方法依赖于手工设计的组件，这些组件限制了性能并增加了复杂性。DETR旨在通过直接集合预测方法简化这一流程。

**2. 试图解决的问题：**

- 解决的问题：传统对象检测方法中的手工设计组件导致性能受限和流程复杂。

**3. 是否是新问题：**

- 不是全新的问题，但提出的解决方案是新颖的，将transformers应用于对象检测任务。

**4. 科学假设：**

- 假设：transformers能够有效地用于对象检测任务，并且能够通过集合预测简化检测流程。

**5. 相关研究：**

- 相关领域包括集合预测、编码器-解码器架构、并行解码和对象检测方法。
- 归类：将DETR归类为直接集合预测方法，与传统的基于锚点或提议的方法相对。
- 值得关注的研究员：论文作者团队，以及在transformers和对象检测领域有重要贡献的研究员。

**6. 解决方案关键：**

- 关键：使用transformer架构进行集合预测，并通过二分图匹配损失进行端到端训练。

**7. 实验设计：**

- 实验设计：在COCO数据集上评估DETR，并与传统的Faster RCNN方法进行比较。

**8. 数据集与代码开源：**

- 使用的数据集：COCO 2017检测和全景分割数据集。
- 代码开源：是的，训练代码和预训练模型可在GitHub上获得。

**9. 实验结果与科学假设：**

- 实验结果：DETR在COCO数据集上达到了与Faster RCNN相当的性能，尤其是在大物体检测上表现更好。
- 支持假设：结果支持了transformers能够有效进行对象检测的假设。

**10. 论文贡献：**

- 提出了一种新的端到端对象检测框架DETR，简化了对象检测流程，并在COCO数据集上展示了竞争性能。
- 证明了transformers可以有效地应用于对象检测任务。

**11. 下一步工作：**

- 改进DETR在小物体检测上的性能。
- 探索DETR在其他视觉任务中的应用。
- 进一步优化DETR的训练和推理效率。

### 回答问题

1. **这篇论文做了什么工作，它的动机是什么？** 论文提出了一种新的端到端对象检测方法DETR，使用transformers进行集合预测，以简化传统对象检测流程并提高性能。
    
2. **这篇论文试图解决什么问题？** 论文试图解决传统对象检测方法中手工设计组件导致的性能受限和流程复杂的问题。
    
3. **这是否是一个新的问题？** 不是全新的问题，但提出的解决方案是新颖的。
    
4. **这篇文章要验证一个什么科学假设？** 验证transformers能够有效地用于对象检测任务，并且能够通过集合预测简化检测流程的假设。
    
5. **有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？** 相关研究包括集合预测、编码器-解码器架构、并行解码和对象检测方法。DETR归类为直接集合预测方法。值得关注的研究员包括论文作者团队和在transformers及对象检测领域有重要贡献的研究员。
    
6. **论文中提到的解决方案之关键是什么？** 解决方案的关键是使用transformer架构进行集合预测，并通过二分图匹配损失进行端到端训练。
    
7. **论文中的实验是如何设计的？** 实验设计是在COCO数据集上评估DETR，并与传统的Faster RCNN方法进行比较。
    
8. **用于定量评估的数据集上什么？代码有没有开源？** 使用的数据集是COCO 2017检测和全景分割数据集。代码已经在GitHub上开源。
    
9. **论文中的实验及结果有没有很好地支持需要验证的科学假设？** 实验结果支持了transformers能够有效进行对象检测的假设，尤其是在大物体检测上表现更好。
    
10. **这篇论文到底有什么贡献？** 论文提出了一种新的端到端对象检测框架DETR，简化了对象检测流程，并在COCO数据集上展示了竞争性能，证明了transformers可以有效地应用于对象检测任务。
    
11. **下一步呢？有什么工作可以继续深入？** 下一步的工作可以包括改进DETR在小物体检测上的性能，探索DETR在其他视觉任务中的应用，以及进一步优化DETR的训练和推理效率。

---

