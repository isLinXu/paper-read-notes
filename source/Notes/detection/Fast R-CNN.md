# Fast R-CNN
**标题：** Fast R-CNN

**作者：** Ross Girshick (Microsoft Research)

**摘要：**

- 论文提出了一种名为Fast R-CNN的目标检测方法，该方法在前人工作的基础上，通过使用深度卷积网络对目标提议进行分类，并引入多项创新来提高训练和测试速度，同时增加检测精度。
- Fast R-CNN在训练VGG16网络时比R-CNN快9倍，在测试时快213倍，并且在PASCAL VOC 2012数据集上达到了更高的mAP。

**1. 解决的问题：**

- 论文旨在解决目标检测任务中存在的效率和准确性问题，特别是针对于R-CNN和SPPnet方法的局限性。

**2. 新问题：**

- 目标检测任务本身不是新问题，但Fast R-CNN提出了一种新的解决方案，以提高检测速度和准确性。

**3. 科学假设：**

- 假设通过单阶段训练算法联合学习分类目标提议和优化空间位置，可以提高目标检测的速度和质量。

**4. 相关研究：**

- 相关研究包括R-CNN和SPPnet等，这些研究主要关注于如何使用深度学习进行目标检测。
- 领域内值得关注的研究员包括Ross Girshick、Kaiming He、Xiangyu Zhang等。

**5. 解决方案关键：**

- 解决方案的关键在于Fast R-CNN的网络架构，特别是引入的感兴趣区域(RoI)池化层，以及多任务损失函数的使用。

**6. 实验设计：**

- 实验使用了PASCAL VOC 2012数据集进行评估，并且对比了R-CNN和SPPnet的性能。
- 作者还探索了不同大小的网络模型（如CaffeNet、VGG CNN M、VGG16）以及单尺度和多尺度训练方法。

**7. 数据集与开源代码：**

- 使用了PASCAL VOC 2007、2010和2012数据集进行定量评估。
- 代码已在GitHub上开源，并且提供了代码的链接：[https://github.com/rbgirshick/fast-rcnn](https://github.com/rbgirshick/fast-rcnn)

**8. 实验结果与假设支持：**

- 实验结果表明，Fast R-CNN在目标检测任务上达到了更高的mAP，并且具有更快的训练和测试速度，这很好地支持了论文提出的科学假设。

**9. 论文贡献：**

- 提出了Fast R-CNN，一种新的快速且准确的目标检测框架。
- 证明了单阶段训练算法的有效性，并且展示了在目标检测任务中使用深度卷积网络的可能性。
- 开源了实现的代码，促进了研究社区的进步。

**10. 下一步工作：**

- 可以继续探索更深层次的网络结构，以及如何进一步减少计算资源消耗。
- 研究如何将Fast R-CNN应用于视频目标检测或其他实时检测任务。
- 探索使用不同目标提议方法对Fast R-CNN性能的影响。

**回答问题：**

1. 论文试图解决目标检测中的效率和准确性问题。
2. 不是新问题，但是对现有问题的改进。
3. 文章要验证的科学假设是通过单阶段训练算法可以提高目标检测的速度和质量。
4. 相关研究包括R-CNN和SPPnet，归类于深度学习在目标检测中的应用。值得关注的研究员包括Ross Girshick等。
5. 解决方案的关键是RoI池化层和多任务损失函数。
6. 实验设计包括使用PASCAL VOC数据集和对比R-CNN与SPPnet。
7. 使用了PASCAL VOC数据集，代码已开源。
8. 是的，实验结果支持了假设。
9. 论文的贡献包括提出了Fast R-CNN框架和开源了相关代码。
10. 下一步工作可以包括探索更深网络结构和减少计算资源消耗的方法。



---

<img width="700" alt="fastrcnn-fig1" src="https://github.com/isLinXu/issues/assets/59380685/7581f87f-0769-4b6f-8f09-53d2ca8cc56a">

该图展示了Fast R-CNN模型的结构及其输入输出。以下是对该模型结构的详细分析，并结合图片的摘要进行整理：

模型结构
1. **输入（Input）**:
   - **输入图像（Input Image）**: 一张输入图像。
   - **兴趣区域（Regions of Interest, RoIs）**: 多个兴趣区域，这些区域是在输入图像中预先确定的。

2. **深度卷积网络（Deep ConvNet）**:
   - 输入图像和兴趣区域被输入到一个全卷积网络中。
   - 卷积网络提取图像的特征图（Conv Feature Map）。

3. **RoI投影（RoI Projection）**:
   - 每个兴趣区域（RoI）被投影到卷积特征图上。
   - 通过RoI池化层（RoI Pooling Layer），每个RoI被池化成固定大小的特征图。

4. **全连接层（Fully Connected Layers, FCs）**:
   - 池化后的RoI特征图被映射到一个特征向量（RoI Feature Vector）。
   - 通过一系列全连接层（FCs），特征向量被进一步处理。

5. **输出（Outputs）**:
   - **分类（Classification）**:
     - 通过softmax层，输出每个RoI的类别概率（softmax probabilities）。
   - **边界框回归（Bounding-Box Regression）**:
     - 通过回归层，输出每个RoI的类别边界框回归偏移量（per-class bounding-box regression offsets）。

训练（Training）
- **多任务损失（Multi-Task Loss）**:
  - 该架构通过多任务损失进行端到端训练，结合了分类损失和边界框回归损失。

摘要
- **图像左侧**:
  - 展示了一张输入图像，其中包含一个骑马的人。
  - 红色框标出了一个兴趣区域（RoI），即图像中的骑马人。

- **图像右侧**:
  - 展示了Fast R-CNN模型的结构流程。
  - 输入图像通过深度卷积网络提取特征图。
  - 兴趣区域通过RoI池化层被池化成固定大小的特征图。
  - 池化后的特征图通过全连接层处理，生成RoI特征向量。
  - 最终输出包括每个RoI的类别概率和边界框回归偏移量。

总结
Fast R-CNN模型通过以下步骤实现目标检测：
1. 输入图像和兴趣区域被输入到全卷积网络中，提取图像的特征图。
2. 每个兴趣区域被投影到特征图上，并通过RoI池化层池化成固定大小的特征图。
3. 池化后的特征图通过全连接层处理，生成RoI特征向量。
4. 最终输出包括每个RoI的类别概率和边界框回归偏移量。

该模型通过多任务损失进行端到端训练，结合了分类和边界框回归任务，显著提高了目标检测的精度和效率。


---

<img width="721" alt="fastrcnn-fig2" src="https://github.com/isLinXu/issues/assets/59380685/e1272122-a672-4ea2-96f5-760d8d35729e">

该图表展示了VGG16模型在前向传播（forward pass）过程中，在应用截断奇异值分解（SVD）前后的时间分布情况。图表通过两个饼图对比了不同层在前向传播中所占用的时间比例，并展示了应用SVD前后的平均精度（mAP）和每张图像的处理时间。以下是对图表内容的详细分析：

图表内容
1. **前向传播时间分布（Forward Pass Timing）**:
   - **左图：应用SVD前**:
     - 平均精度（mAP）：66.9%
     - 每张图像的处理时间：320毫秒
     - 各层时间分布：
       - 卷积层（conv）：46.3%（146毫秒）
       - 全连接层fc6：38.7%（122毫秒）
       - 全连接层fc7：6.2%（20毫秒）
       - RoI池化层（roi_pool5）：5.4%（17毫秒）
       - 其他（other）：3.5%（11毫秒）

   - **右图：应用SVD后**:
     - 平均精度（mAP）：66.6%
     - 每张图像的处理时间：223毫秒
     - 各层时间分布：
       - 卷积层（conv）：67.8%（143毫秒）
       - 全连接层fc6：17.5%（37毫秒）
       - 全连接层fc7：1.7%（4毫秒）
       - RoI池化层（roi_pool5）：5.1%（11毫秒）
       - 其他（other）：7.9%（17毫秒）

图表分析
1. **应用SVD前（左图）**:
   - 全连接层fc6和fc7占用了45%的前向传播时间（分别为38.7%和6.2%）。
   - 卷积层占用了46.3%的时间。
   - RoI池化层和其他层分别占用了5.4%和3.5%的时间。

2. **应用SVD后（右图）**:
   - 全连接层fc6和fc7的时间占比显著减少，分别为17.5%和1.7%。
   - 卷积层的时间占比增加到67.8%。
   - RoI池化层和其他层的时间占比分别为5.1%和7.9%。

总结
- **时间分布变化**:
  - 应用SVD后，全连接层fc6和fc7的时间占比显著减少，从45%降至19.2%（17.5% + 1.7%）。
  - 卷积层的时间占比增加，从46.3%增加到67.8%。
  - RoI池化层的时间占比略有减少，而其他层的时间占比有所增加。

- **处理时间和精度**:
  - 应用SVD后，每张图像的处理时间从320毫秒减少到223毫秒，减少了约30%。
  - 平均精度（mAP）略有下降，从66.9%降至66.6%，但精度损失较小。

- **性能提升**:
  - 应用SVD显著减少了全连接层的计算时间，提高了模型的处理效率。
  - 尽管精度略有下降，但处理时间的显著减少使得应用SVD在实际应用中具有较大的优势。

通过这些图表，可以清晰地看到应用SVD前后VGG16模型在前向传播过程中时间分布的变化，揭示了SVD在提高模型计算效率方面的有效性。


---

<img width="601" alt="fastrcnn-fig3" src="https://github.com/isLinXu/issues/assets/59380685/c8341507-19ce-4d5b-b2b4-6b5d9d176230">

该图表展示了在不同目标提议方案下，VOC07测试集的平均精度（mAP）和平均召回率（AR）随目标提议数量变化的情况。图表中使用了多种目标提议方案，并对比了它们在不同目标提议数量下的性能。以下是对图表内容的详细分析和总结：

图表内容
1. **横轴（X轴）**:
   - 目标提议数量（Number of object proposals），范围从10^3到10^4。

2. **左纵轴（Y轴）**:
   - 平均精度（mAP），范围从49到66。

3. **右纵轴（Y轴）**:
   - 平均召回率（Average Recall, AR），范围从49到66。

4. **曲线和标记**:
   - **红色实线**: 选择性搜索（Selective Search, SS）的平均召回率（SS Avg. Recall）。
   - **蓝色实线**: 选择性搜索（SS）的平均精度（mAP）。
   - **蓝色虚线**: SS（2k）+随机密集（Rand Dense）的平均精度（mAP）。
   - **蓝色三角形标记**: SS替换密集（SS replace Dense）的平均精度（mAP）。
   - **蓝色菱形标记**: 45k密集Softmax（45k Dense Softmax）的平均精度（mAP）。
   - **蓝色圆形标记**: 45k密集SVM（45k Dense SVM）的平均精度（mAP）。

图表分析
1. **选择性搜索（SS）**:
   - 平均精度（mAP）随着目标提议数量的增加略有上升，但在大约2000个目标提议后趋于平稳。
   - 平均召回率（AR）随着目标提议数量的增加显著上升，达到约63。

2. **SS（2k）+随机密集（Rand Dense）**:
   - 平均精度（mAP）在目标提议数量增加时略有下降。

3. **SS替换密集（SS replace Dense）**:
   - 平均精度（mAP）在目标提议数量增加时略有下降。

4. **45k密集Softmax（45k Dense Softmax）**:
   - 平均精度（mAP）在目标提议数量增加时显著下降。

5. **45k密集SVM（45k Dense SVM）**:
   - 平均精度（mAP）在目标提议数量增加时显著下降。

总结
- **选择性搜索（SS）**:
  - 选择性搜索在目标提议数量增加时，平均精度（mAP）略有上升并趋于平稳，而平均召回率（AR）显著上升，表明选择性搜索在增加目标提议数量时能够有效提高召回率。

- **其他方案**:
  - SS（2k）+随机密集、SS替换密集、45k密集Softmax和45k密集SVM在目标提议数量增加时，平均精度（mAP）均有所下降，尤其是45k密集Softmax和45k密集SVM下降显著。

- **性能对比**:
  - 选择性搜索（SS）在目标提议数量增加时表现出较好的平衡，能够在提高召回率的同时保持较高的平均精度。
  - 其他方案在目标提议数量增加时，虽然可能提高了召回率，但平均精度有所下降，表明这些方案在处理大量目标提议时可能存在过拟合或噪声问题。

通过这些图表，可以清晰地看到不同目标提议方案在不同目标提议数量下的性能变化，揭示了选择性搜索在目标检测任务中的优势。

