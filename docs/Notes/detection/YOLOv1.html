
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>YOLOv1 &#8212; 论文阅读笔记</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css?v=7f9a90b1" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=40d2fe7a"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Notes/detection/YOLOv1';</script>
    <link rel="icon" href="../../_static/panda.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="YOLOv2" href="YOLOv2.html" />
    <link rel="prev" title="RetinaNet" href="RetinaNet.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="论文阅读笔记 - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="论文阅读笔记 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Method/index.html">论文阅读指南</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Method/efficent_read_paper.html">高效阅读方法及流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/how_to_read_paper.html">如何阅读论文</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/paper_10_question.html">论文速读十问</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/read_important_tips.html">读论文与口头报告的几项重点</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Method/reference.html">参考材料</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../List/index.html">论文阅读清单</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../List/basis.html">神经网络基础(basis)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/attention.html">注意力部分(attention)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/batch_normalization.html">批量&amp;正则化(batch&amp;normalization)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/classification.html">图像分类(CLAS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/convolutional.html">高级卷积网络知识(Convolutional)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/gan.html">AI合成部分(GAN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/nlp.html">自然语言处理(NLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/objectdetection.html">目标检测(OBJ)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../List/rnn.html">循环神经网络(RNN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/segementation.html">目标分割(SEG)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/transformer.html">Transformer</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/multimodal.html">多模态(MultiModal Learning)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../List/llm.html">大语言模型(Large Language Models)</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">论文阅读笔记</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../mm-l/index.html">多模态(MultiModal Machine Learning)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mm-l/blip-v1.html">BLIP: Bootstrapping Language-Image Pre-training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mm-l/blip-v2.html">BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../llm/index.html">大语言模型(Large Language Models)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../llm/opt.html">OPT: OPT : Open Pre-trained Transformer Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v1.html">GPT-v1:Improving Language Understanding by Generative Pre-Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v2.html">GPT-v2:Language Models are Unsupervised Multitask Learners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v3.html">GPT-v3:Language Models are Few-Shot Learners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llm/gpt-v4.html">GPT-v4:GPT-4 Technical Report</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">detection</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="survey_all.html">survey_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="RCNN.html">RCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Fast%20R-CNN.html">Fast R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Faster%20R-CNN.html">Faster R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mask%20R-CNN.html">Mask R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="FCN.html">FCN</a></li>
<li class="toctree-l3"><a class="reference internal" href="FPN.html">FPN</a></li>
<li class="toctree-l3"><a class="reference internal" href="SSD.html">SSD</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mobilenet-SSDv2.html">Mobilenet-SSDv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="Mask%20R-CNN.html">Mask R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="Cascade-RCNN.html">Cascade-RCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="RetinaNet.html">RetinaNet</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">YOLOv1</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv2.html">YOLOv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv3.html">YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv4.html">YOLOv4</a></li>
<li class="toctree-l3"><a class="reference internal" href="ASFF.html">ASFF</a></li>
<li class="toctree-l3"><a class="reference internal" href="ATSS.html">ATSS</a></li>
<li class="toctree-l3"><a class="reference internal" href="SABL.html">SABL</a></li>
<li class="toctree-l3"><a class="reference internal" href="SM-NAS.html">SM-NAS</a></li>
<li class="toctree-l3"><a class="reference internal" href="TSD.html">TSD</a></li>
<li class="toctree-l3"><a class="reference internal" href="RDSNet.html">RDSNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="CenterMask.html">CenterMask</a></li>
<li class="toctree-l3"><a class="reference internal" href="Scaled-YOLOv4.html">Scaled-YOLOv4</a></li>
<li class="toctree-l3"><a class="reference internal" href="Simple%20Multi-dataset%20Detection.html">Simple Multi-dataset Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOX.html">YOLOX</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv6.html">YOLOv6</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOv1.html">PP-YOLOv1</a></li>
<li class="toctree-l3"><a class="reference internal" href="PP-YOLOv2.html">PP-YOLOv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOF.html">YOLOF</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOP.html">YOLOP</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOR.html">YOLOR</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOS.html">YOLOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv7.html">YOLOv7</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv6_v3.0.html">YOLOv6</a></li>
<li class="toctree-l3"><a class="reference internal" href="DAMO-YOLO.html">DAMO-YOLO</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOv9.html">YOLOv9</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOOC.html">YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel Class Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="OWL-ViT.html">OWL-ViT</a></li>
<li class="toctree-l3"><a class="reference internal" href="OWLv2.html">OWLv2</a></li>
<li class="toctree-l3"><a class="reference internal" href="RTMDet.html">RTMDet</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLO-World.html">YOLO-World</a></li>
<li class="toctree-l3"><a class="reference internal" href="YOLOOC.html">YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel Class Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="MDETR.html">MDETR</a></li>
<li class="toctree-l3"><a class="reference internal" href="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B020%E5%B9%B4.html"><strong>目标检测二十年：一项综述</strong></a></li>





<li class="toctree-l3"><a class="reference internal" href="yolo%E7%BB%BC%E8%BF%B0.html"><strong>YOLO的全面综述：从YOLOv1到YOLOv8及未来</strong></a></li>




















</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Read/index.html">论文阅读记录</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Summary/index.html">论文阅读总结</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes/edit/main/Notes/detection/YOLOv1.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isLinXu/paper-read-notes/issues/new?title=Issue%20on%20page%20%2FNotes/detection/YOLOv1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/Notes/detection/YOLOv1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>YOLOv1</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="yolov1">
<h1>YOLOv1<a class="headerlink" href="#yolov1" title="Link to this heading">#</a></h1>
<p><strong>标题：</strong> You Only Look Once: Unified, Real-Time Object Detection</p>
<p><strong>作者：</strong> Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi</p>
<p><strong>单位：</strong> University of Washington, Allen Institute for AI, Facebook AI Research</p>
<p><strong>网址：</strong> http://pjreddie.com/yolo/</p>
<p><strong>摘要：</strong>
本文提出了一种新的目标检测方法，称为YOLO（You Only Look Once）。与传统的目标检测方法不同，YOLO将目标检测视为一个回归问题，直接从图像像素到边界框坐标和类别概率。YOLO使用单个神经网络直接从整幅图像中预测边界框和类别概率。由于整个检测流程是一个单一的网络，它可以在检测性能上进行端到端的直接优化。YOLO的统一架构非常快速，基础YOLO模型以45帧每秒的速度实时处理图像。一个更小版本的网络，Fast YOLO，以155帧每秒处理图像，同时仍然达到其他实时检测器平均精度（mAP）的两倍。与最先进的检测系统相比，YOLO在定位上可能会犯更多错误，但在背景上预测误报的可能性较小。最后，YOLO学习到的是非常通用的目标表示。在从自然图像泛化到其他领域（如艺术品）时，YOLO的表现超过了其他检测方法，包括DPM和R-CNN。</p>
<p><strong>1、这篇论文试图解决什么问题：</strong>
论文试图解决目标检测领域的实时性和准确性问题。传统的目标检测方法通常需要复杂的流程和多个独立训练的组件，这使得它们在速度和优化上存在限制。YOLO旨在通过单一神经网络实现快速且准确的目标检测。</p>
<p><strong>2、这是否是一个新的问题：</strong>
这不是一个全新的问题，目标检测是计算机视觉中长期存在的研究问题。然而，YOLO提出了一种新的解决方案，即通过单一网络实现实时目标检测，这在当时是具有创新性的。</p>
<p><strong>3、这篇文章要验证一个什么科学假设：</strong>
文章的核心科学假设是，通过将目标检测框架为一个回归问题，并使用单一神经网络进行端到端的训练，可以创建一个既快速又准确的目标检测系统。</p>
<p><strong>4、有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</strong>
相关研究包括：</p>
<ul class="simple">
<li><p>Deformable Parts Models (DPM)</p></li>
<li><p>R-CNN系列（包括Fast R-CNN和Faster R-CNN）</p></li>
<li><p>OverFeat</p></li>
<li><p>MultiBox
这些研究可以归类为使用深度学习进行目标检测的不同方法。领域内值得关注的研究员包括Joseph Redmon、Ross Girshick、Ali Farhadi等。</p></li>
</ul>
<p><strong>5、论文中提到的解决方案之关键是什么：</strong>
解决方案的关键是将目标检测作为图像像素到边界框坐标和类别概率的回归问题，并使用单个卷积神经网络（CNN）进行端到端的训练。</p>
<p><strong>6、论文中的实验是如何设计的：</strong>
实验设计包括在PASCAL VOC数据集上评估YOLO与其他实时检测系统的性能和速度。此外，还包括对Fast R-CNN检测结果使用YOLO进行重分（rescoring）的实验，以及在艺术品数据集上测试YOLO的泛化能力。</p>
<p><strong>7、用于定量评估的数据集上什么？代码有没有开源？</strong>
用于定量评估的数据集包括PASCAL VOC 2007和VOC 2012。代码已经开源，可以在论文提供的网址上找到。</p>
<p><strong>8、论文中的实验及结果有没有很好地支持需要验证的科学假设？</strong>
是的，实验结果支持了科学假设。YOLO在速度上达到了实时性能，并且在mAP上超过了其他实时检测系统。此外，YOLO在艺术品数据集上的表现也证明了其良好的泛化能力。</p>
<p><strong>9、这篇论文到底有什么贡献？</strong>
论文的贡献包括：</p>
<ul class="simple">
<li><p>提出了YOLO，一种新的实时目标检测框架，它通过单一网络实现快速且准确的目标检测。</p></li>
<li><p>证明了YOLO在PASCAL VOC数据集上具有良好的性能，并且在艺术品数据集上展现了优秀的泛化能力。</p></li>
<li><p>开源了YOLO的代码和预训练模型，为后续研究提供了工具和数据。</p></li>
</ul>
<p><strong>10、下一步呢？有什么工作可以继续深入？</strong>
下一步的工作可能包括：</p>
<ul class="simple">
<li><p>改进YOLO的网络结构，以提高对小目标和密集目标的检测性能。</p></li>
<li><p>探索YOLO在其他领域的应用，如视频分析、机器人视觉等。</p></li>
<li><p>进一步研究如何结合YOLO与其他目标检测方法，以提高整体性能。</p></li>
<li><p>开发更复杂的数据增强技术，以提高YOLO的泛化能力。</p></li>
</ul>
<hr class="docutils" />
<img width="794" alt="yolov1-fig1" src="https://github.com/isLinXu/issues/assets/59380685/ff203269-cdc9-47cc-8102-fd247c158a3c">
<p>YOLO检测系统的工作流程可以总结为以下几个步骤：</p>
<ol class="arabic simple">
<li><p><strong>调整图像大小</strong>：</p>
<ul class="simple">
<li><p>将输入图像调整为固定尺寸（如 448×448448×448），以便于后续处理。</p></li>
</ul>
</li>
<li><p><strong>运行卷积神经网络</strong>：</p>
<ul class="simple">
<li><p>使用一个单一的卷积神经网络对调整大小后的图像进行处理。</p></li>
<li><p>CNN提取图像特征并进行目标检测，输出多个边界框和对应的置信度分数。</p></li>
</ul>
</li>
<li><p><strong>非极大值抑制</strong>：</p>
<ul class="simple">
<li><p>对检测结果进行阈值处理，保留置信度高的检测结果，去除重叠的检测框。</p></li>
<li><p>最终输出目标的边界框和置信度分数。</p></li>
</ul>
</li>
</ol>
<p>结论</p>
<ul class="simple">
<li><p><strong>YOLO检测系统</strong>：YOLO是一种高效的目标检测系统，通过单次前向传播即可完成目标检测任务。</p></li>
<li><p><strong>处理步骤</strong>：包括调整图像大小、运行卷积神经网络和非极大值抑制三个主要步骤。</p></li>
<li><p><strong>优点</strong>：YOLO的处理流程简单直接，能够实时检测图像中的目标，适用于需要快速目标检测的应用场景。</p></li>
</ul>
<p>YOLO检测系统的设计使其在保持高检测精度的同时，具有较高的计算效率，适用于实时目标检测任务。</p>
<hr class="docutils" />
<img width="679" alt="yolov1-fig2" src="https://github.com/isLinXu/issues/assets/59380685/29ca87a9-fe59-4b41-883b-c2492aac18b7">
<p>YOLO模型-输入输出流程</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：</p>
<ul class="simple">
<li><p>输入图像（如图中所示的包含狗和自行车的图像）。</p></li>
</ul>
</li>
<li><p><strong>图像划分</strong>：</p>
<ul class="simple">
<li><p>将输入图像划分为S×S 的网格。</p></li>
<li><p>每个网格单元负责预测其覆盖区域内的目标。</p></li>
</ul>
</li>
<li><p><strong>卷积神经网络</strong>：</p>
<ul class="simple">
<li><p>使用卷积神经网络（CNN）对图像进行处理，提取特征。</p></li>
<li><p>CNN输出一个S×S×(B×5+C) 的张量。</p></li>
</ul>
</li>
<li><p><strong>边界框和类别预测</strong>：</p>
<ul class="simple">
<li><p>每个网格单元预测 B 个边界框，每个边界框包含5个参数（x, y, w, h, 置信度）。</p></li>
<li><p>每个网格单元还预测 C 个类别的概率。</p></li>
</ul>
</li>
<li><p><strong>非极大值抑制（Non-max suppression）</strong>：</p>
<ul class="simple">
<li><p>对预测结果进行阈值处理，保留置信度高的检测结果，去除重叠的检测框。</p></li>
</ul>
</li>
<li><p><strong>输出</strong>：</p>
<ul class="simple">
<li><p>最终输出目标的边界框和类别标签（如图中所示的狗和自行车的边界框和类别标签）。</p></li>
</ul>
</li>
</ol>
<p>结论</p>
<ul class="simple">
<li><p><strong>YOLO模型</strong>：YOLO将目标检测问题建模为一个回归问题，通过单次前向传播完成目标检测任务。</p></li>
<li><p><strong>处理步骤</strong>：包括图像划分、卷积神经网络处理、边界框和类别预测、非极大值抑制等步骤。</p></li>
<li><p><strong>优点</strong>：YOLO的处理流程简单直接，能够实时检测图像中的目标，适用于需要快速目标检测的应用场景。</p></li>
</ul>
<hr class="docutils" />
<img width="1359" alt="yolov1-fig3" src="https://github.com/isLinXu/issues/assets/59380685/d36948d1-d32b-483d-ae78-1029c73d7080">
<p>网络模型结构分析</p>
<p>图表展示了YOLO（You Only Look Once）目标检测模型的网络架构。该网络由24个卷积层和2个全连接层组成。以下是对图表内容的详细分析和总结。</p>
<p>网络结构</p>
<ol class="arabic simple">
<li><p><strong>输入图像</strong>：</p>
<ul class="simple">
<li><p>输入图像的尺寸为 (448 \times 448 \times 3)（宽度、高度和通道数）。</p></li>
</ul>
</li>
<li><p><strong>卷积层和池化层</strong>：</p>
<ul class="simple">
<li><p><strong>Conv. Layer 1</strong>：卷积核大小为 (7 \times 7)，步长为2，输出特征图尺寸为 (224 \times 224 \times 64)。</p></li>
<li><p><strong>Maxpool Layer 1</strong>：池化核大小为 (2 \times 2)，步长为2，输出特征图尺寸为 (112 \times 112 \times 64)。</p></li>
<li><p><strong>Conv. Layer 2</strong>：卷积核大小为 (3 \times 3)，步长为1，输出特征图尺寸为 (112 \times 112 \times 192)。</p></li>
<li><p><strong>Maxpool Layer 2</strong>：池化核大小为 (2 \times 2)，步长为2，输出特征图尺寸为 (56 \times 56 \times 192)。</p></li>
<li><p><strong>Conv. Layers 3-5</strong>：卷积核大小为 (3 \times 3)，步长为1，输出特征图尺寸为 (56 \times 56 \times 128) 和 (28 \times 28 \times 256)。</p></li>
<li><p><strong>Maxpool Layer 3</strong>：池化核大小为 (2 \times 2)，步长为2，输出特征图尺寸为 (28 \times 28 \times 256)。</p></li>
<li><p><strong>Conv. Layers 6-8</strong>：卷积核大小为 (3 \times 3)，步长为1，输出特征图尺寸为 (28 \times 28 \times 256) 和 (14 \times 14 \times 512)。</p></li>
<li><p><strong>Maxpool Layer 4</strong>：池化核大小为 (2 \times 2)，步长为2，输出特征图尺寸为 (14 \times 14 \times 512)。</p></li>
<li><p><strong>Conv. Layers 9-11</strong>：卷积核大小为 (3 \times 3)，步长为1，输出特征图尺寸为 (14 \times 14 \times 512) 和 (7 \times 7 \times 1024)。</p></li>
<li><p><strong>Maxpool Layer 5</strong>：池化核大小为 (2 \times 2)，步长为2，输出特征图尺寸为 (7 \times 7 \times 1024)。</p></li>
<li><p><strong>Conv. Layers 12-24</strong>：卷积核大小为 (3 \times 3) 和 (1 \times 1) 交替，步长为1，输出特征图尺寸为 (7 \times 7 \times 1024)。</p></li>
</ul>
</li>
<li><p><strong>全连接层</strong>：</p>
<ul class="simple">
<li><p><strong>Fully Connected Layer 1</strong>：输出尺寸为4096。</p></li>
<li><p><strong>Fully Connected Layer 2</strong>：输出尺寸为4096。</p></li>
</ul>
</li>
<li><p><strong>输出层</strong>：</p>
<ul class="simple">
<li><p>最终输出为一个 (S \times S \times (B \times 5 + C)) 的张量，其中 (S) 是网格大小，(B) 是每个网格单元预测的边界框数量，(C) 是类别数量。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>网络架构</strong>：YOLO模型由24个卷积层和2个全连接层组成，卷积层和池化层交替使用，以逐步减少特征图的空间尺寸并增加特征图的深度。</p></li>
<li><p><strong>卷积层</strong>：使用不同大小的卷积核（如 (7 \times 7), (3 \times 3), (1 \times 1)）来提取图像特征。</p></li>
<li><p><strong>池化层</strong>：使用最大池化层（Maxpool）来减少特征图的空间尺寸。</p></li>
<li><p><strong>全连接层</strong>：在卷积层之后，使用两个全连接层来进一步处理特征图。</p></li>
<li><p><strong>输出层</strong>：最终输出为一个 (S \times S \times (B \times 5 + C)) 的张量，包含每个网格单元的边界框和类别预测。</p></li>
</ul>
<p>结论</p>
<p>YOLO模型的网络架构设计使其能够高效地提取图像特征并进行目标检测。通过交替使用卷积层和池化层，逐步减少特征图的空间尺寸并增加其深度，最终通过全连接层和输出层生成目标检测结果。该架构在保持高检测精度的同时，具有较高的计算效率，适用于实时目标检测任务。</p>
<hr class="docutils" />
<p>Fast R-CNN与YOLO的错误分析</p>
<img width="672" alt="yolov1-fig4" src="https://github.com/isLinXu/issues/assets/59380685/a2f47f4c-a5ba-4108-9b82-f2b2c3e7ca40">
<p>图表展示了Fast R-CNN和YOLO模型在目标检测任务中的错误分析。饼图显示了在检测结果中不同类型错误的百分比，包括定位错误（Localization errors）、背景错误（Background errors）、相似性错误（Similarity errors）和其他错误（Other errors）。以下是对图表内容的详细分析和总结。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>Fast R-CNN</strong>：</p>
<ul class="simple">
<li><p><strong>正确检测（Correct）</strong>：71.6%</p></li>
<li><p><strong>定位错误（Loc）</strong>：8.6%</p></li>
<li><p><strong>背景错误（Background）</strong>：13.6%</p></li>
<li><p><strong>相似性错误（Sim）</strong>：4.3%</p></li>
<li><p><strong>其他错误（Other）</strong>：1.9%</p></li>
</ul>
</li>
<li><p><strong>YOLO</strong>：</p>
<ul class="simple">
<li><p><strong>正确检测（Correct）</strong>：65.5%</p></li>
<li><p><strong>定位错误（Loc）</strong>：19.0%</p></li>
<li><p><strong>背景错误（Background）</strong>：4.75%</p></li>
<li><p><strong>相似性错误（Sim）</strong>：6.75%</p></li>
<li><p><strong>其他错误（Other）</strong>：4.0%</p></li>
</ul>
</li>
</ol>
<p>错误类型分析</p>
<ol class="arabic simple">
<li><p><strong>正确检测（Correct）</strong>：</p>
<ul class="simple">
<li><p>Fast R-CNN的正确检测率为71.6%，高于YOLO的65.5%。</p></li>
<li><p>这表明在检测结果中，Fast R-CNN的准确性略高于YOLO。</p></li>
</ul>
</li>
<li><p><strong>定位错误（Loc）</strong>：</p>
<ul class="simple">
<li><p>YOLO的定位错误率为19.0%，显著高于Fast R-CNN的8.6%。</p></li>
<li><p>这表明YOLO在目标定位方面存在更多的误差，可能是由于其一次性检测方法导致的。</p></li>
</ul>
</li>
<li><p><strong>背景错误（Background）</strong>：</p>
<ul class="simple">
<li><p>Fast R-CNN的背景错误率为13.6%，显著高于YOLO的4.75%。</p></li>
<li><p>这表明Fast R-CNN更容易将背景误检测为目标对象，而YOLO在这方面表现更好。</p></li>
</ul>
</li>
<li><p><strong>相似性错误（Sim）</strong>：</p>
<ul class="simple">
<li><p>YOLO的相似性错误率为6.75%，高于Fast R-CNN的4.3%。</p></li>
<li><p>这表明YOLO在区分相似类别的目标时存在更多的误差。</p></li>
</ul>
</li>
<li><p><strong>其他错误（Other）</strong>：</p>
<ul class="simple">
<li><p>YOLO的其他错误率为4.0%，高于Fast R-CNN的1.9%。</p></li>
<li><p>这表明YOLO在其他类型的错误上也比Fast R-CNN更多。</p></li>
</ul>
</li>
</ol>
<p>总结</p>
<ul class="simple">
<li><p><strong>Fast R-CNN的优势</strong>：</p>
<ul>
<li><p>Fast R-CNN在正确检测率上略高于YOLO，表现出更高的准确性。</p></li>
<li><p>Fast R-CNN在定位错误和相似性错误方面表现更好，误差较少。</p></li>
</ul>
</li>
<li><p><strong>YOLO的优势</strong>：</p>
<ul>
<li><p>YOLO在背景错误方面表现更好，误检测背景为目标的情况较少。</p></li>
<li><p>YOLO的检测速度通常比Fast R-CNN更快，适用于实时检测任务。</p></li>
</ul>
</li>
<li><p><strong>改进空间</strong>：</p>
<ul>
<li><p>YOLO需要改进其定位精度，以减少定位错误。</p></li>
<li><p>Fast R-CNN需要改进其背景检测能力，以减少背景错误。</p></li>
</ul>
</li>
</ul>
<p>结论
通过对Fast R-CNN和YOLO的错误分析，可以看出两者在不同类型错误上的表现各有优劣。Fast R-CNN在定位和相似性错误方面表现更好，而YOLO在背景错误方面表现更好。根据具体应用场景的需求，可以选择合适的模型进行目标检测任务。</p>
<hr class="docutils" />
<img width="1367" alt="yolov1-fig5" src="https://github.com/isLinXu/issues/assets/59380685/2c786a8d-03e5-41b7-8632-c1dbf8ad1c00">
<p>图表展示了YOLO模型在不同数据集上的性能表现，包括精确率-召回率曲线和定量结果表格。以下是对图表内容的详细分析和总结。</p>
<p>图表内容</p>
<ol class="arabic simple">
<li><p><strong>精确率-召回率曲线（Precision-Recall Curve）</strong>：</p>
<ul class="simple">
<li><p>图表左侧显示了在Picasso数据集上的精确率-召回率曲线。</p></li>
<li><p>曲线展示了不同模型在不同召回率下的精确率表现。</p></li>
<li><p>不同颜色的曲线代表不同的模型，包括YOLO、R-CNN、DPM、Poselets和D&amp;T。</p></li>
</ul>
</li>
<li><p><strong>定量结果表格</strong>：</p>
<ul class="simple">
<li><p>图表右侧显示了在VOC 2007、Picasso和People-Art数据集上的定量结果。</p></li>
<li><p>表格中列出了不同模型在各个数据集上的平均精度（AP）和最佳F1分数（Best �1F1​）。</p></li>
</ul>
</li>
</ol>
<p>精确率-召回率曲线分析</p>
<ul class="simple">
<li><p><strong>YOLO</strong>：</p>
<ul>
<li><p>在大部分召回率范围内，YOLO的精确率较高，曲线位于图表的上方，表现出较好的性能。</p></li>
</ul>
</li>
<li><p><strong>R-CNN</strong>：</p>
<ul>
<li><p>R-CNN的曲线在中高召回率范围内表现较好，但在低召回率范围内精确率较低。</p></li>
</ul>
</li>
<li><p><strong>DPM</strong>：</p>
<ul>
<li><p>DPM的曲线在中低召回率范围内表现较好，但整体精确率不如YOLO和R-CNN。</p></li>
</ul>
</li>
<li><p><strong>Poselets</strong>：</p>
<ul>
<li><p>Poselets的曲线在大部分召回率范围内精确率较低，表现不如其他模型。</p></li>
</ul>
</li>
<li><p><strong>D&amp;T</strong>：</p>
<ul>
<li><p>D&amp;T的曲线在所有召回率范围内精确率最低，表现最差。</p></li>
</ul>
</li>
</ul>
<p>定量结果表格分析</p>
<ul class="simple">
<li><p><strong>VOC 2007数据集</strong>：</p>
<ul>
<li><p>YOLO的平均精度（AP）为59.2%，高于其他模型。</p></li>
<li><p>R-CNN的AP为54.2%，次于YOLO。</p></li>
<li><p>DPM和Poselets的AP分别为43.2%和36.5%，表现较差。</p></li>
<li><p>D&amp;T的AP为16.0%，表现最差。</p></li>
</ul>
</li>
<li><p><strong>Picasso数据集</strong>：</p>
<ul>
<li><p>YOLO的AP为53.3%，最佳F1分数为0.590，表现最好。</p></li>
<li><p>R-CNN的AP为10.4%，最佳F1分数为0.226，次于YOLO。</p></li>
<li><p>DPM和Poselets的AP分别为37.8%和17.8%，最佳F1分数分别为0.458和0.271，表现较差。</p></li>
<li><p>D&amp;T的AP为1.9%，最佳F1分数为0.051，表现最差。</p></li>
</ul>
</li>
<li><p><strong>People-Art数据集</strong>：</p>
<ul>
<li><p>YOLO的AP为45，表现最好。</p></li>
<li><p>R-CNN的AP为26，次于YOLO。</p></li>
<li><p>DPM和Poselets的AP分别为32和32，表现较差。</p></li>
</ul>
</li>
</ul>
<p>结论</p>
<ul class="simple">
<li><p><strong>YOLO模型的优势</strong>：</p>
<ul>
<li><p>在不同数据集上，YOLO模型的平均精度（AP）和最佳F1分数均表现出色，优于其他模型。</p></li>
<li><p>在精确率-召回率曲线中，YOLO在大部分召回率范围内的精确率较高，表现出较好的性能。</p></li>
</ul>
</li>
<li><p><strong>其他模型的表现</strong>：</p>
<ul>
<li><p>R-CNN在部分数据集上表现较好，但整体不如YOLO。</p></li>
<li><p>DPM和Poselets在所有数据集上的表现均不如YOLO和R-CNN。</p></li>
<li><p>D&amp;T在所有数据集上的表现最差。</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<img width="1371" alt="yolov1-fig6" src="https://github.com/isLinXu/issues/assets/59380685/8cd17d58-dff5-408c-b29e-f3434693b80a">
<p>误检分析</p>
<ul class="simple">
<li><p><strong>误检情况</strong>：</p>
<ul>
<li><p>在某些情况下，YOLO模型会出现误检。例如，在第二幅自然图像中，YOLO将一个人误检测为一架飞机。</p></li>
</ul>
</li>
</ul>
<p>总结</p>
<ul class="simple">
<li><p><strong>YOLO模型的优势</strong>：</p>
<ul>
<li><p>YOLO模型在大多数情况下能够准确检测并标注图像中的目标对象。</p></li>
<li><p>无论是艺术作品还是自然图像，YOLO模型都展示了较高的检测精度。</p></li>
</ul>
</li>
<li><p><strong>误检和改进空间</strong>：</p>
<ul>
<li><p>尽管YOLO模型在大多数情况下表现良好，但仍存在误检情况，需要进一步改进模型以提高检测精度。</p></li>
</ul>
</li>
</ul>
<p>结论</p>
<p>YOLO模型在艺术作品和自然图像上的检测结果展示了其强大的目标检测能力。尽管存在一些误检情况，但整体表现出色，能够准确检测并标注图像中的目标对象。通过进一步优化和改进，YOLO模型有望在更多复杂场景中实现更高的检测精度。</p>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="RetinaNet.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">RetinaNet</p>
      </div>
    </a>
    <a class="right-next"
       href="YOLOv2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">YOLOv2</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By isLinXu
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022, isLinXu.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>